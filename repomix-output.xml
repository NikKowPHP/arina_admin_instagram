This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.roo/
  rules-architect-senior/
    rules.md
  rules-developer/
    rules.md
  rules-emergency/
    rules.md
  rules-orchestrator-senior/
    rules.md
  rules-planner-architect/
    rules.md
  rules-planner-orchestrator/
    rules.md
  custom_modes.yaml
admin/
  admin/
    prisma/
      schema.prisma
    public/
      file.svg
      globe.svg
      next.svg
      vercel.svg
      window.svg
    src/
      app/
        dashboard/
          triggers/
            page.tsx
          page.tsx
        globals.css
        layout.tsx
        page.tsx
      components/
        ui/
          bar-chart.tsx
          button.tsx
          card.tsx
          line-chart.tsx
          pie-chart.tsx
        bot-health-status.tsx
        chart-controls.tsx
      lib/
        actions.ts
        supabase-provider.tsx
        supabase.ts
        utils.ts
        validators.ts
      types/
        bot-monitor.ts
        supabase.ts
    .gitignore
    eslint.config.mjs
    next.config.ts
    package.json
    postcss.config.mjs
    README.md
    repomix-output.xml
    tsconfig.json
bot-monitor/
  service.ts
  types.ts
documentation/
  api_spec.md
  business_requirements.md
  database_schema.md
  deployment_guide.md
  functional_requirements.md
  master_plan.md
  technical_design.md
supabase/
  .gitignore
  config.toml
todos/
  dev_todo_phase_1.md
  dev_todo_phase_10.md
  dev_todo_phase_11.md
  dev_todo_phase_12.md
  dev_todo_phase_2.md
  dev_todo_phase_3.md
  dev_todo_phase_4.md
  dev_todo_phase_5.md
  dev_todo_phase_6.md
  dev_todo_phase_7.md
  dev_todo_phase_8.md
  dev_todo_phase_9.md
  master_development_plan.md
app_description.md
docker-compose.yml
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="todos/dev_todo_phase_10.md">
# Phase 10: REST API for Trigger Management

## 1. Create API Route Structure
- **Create `admin/admin/src/app/api/triggers/route.ts`**:
  - Implement handlers for:
    - GET /api/triggers (list triggers)
    - POST /api/triggers (create trigger)
    - GET /api/triggers/[id] (get single trigger)
    - PUT /api/triggers/[id] (update trigger)
    - DELETE /api/triggers/[id] (delete trigger)

## 2. Implement CRUD Operations
- **Connect to Prisma ORM**:
  - Use existing Prisma client to interact with database
  - Add error handling for database operations
- **Implement validation**:
  - Reuse validators from `src/lib/validators.ts`
  - Add input sanitization

## 3. Add Authentication
- **Protect API routes**:
  - Integrate with NextAuth.js middleware
  - Require valid session for all trigger operations
- **Add role-based access control**:
  - Only allow admin users to modify triggers

## 4. Implement Rate Limiting
- **Add rate limiting middleware**:
  - Limit to 100 requests/minute per IP
  - Use Redis for distributed rate limiting

## 5. Add Documentation
- **Create OpenAPI spec**:
  - Document all endpoints in `documentation/api_spec.md`
  - Include request/response examples

## 6. Testing
- **Write integration tests**:
  - Test all CRUD operations
  - Test authentication and authorization
  - Test rate limiting
</file>

<file path="todos/dev_todo_phase_11.md">
# Phase 11: REST API for Template Operations

## 1. Create API Route Structure
- **Create `admin/admin/src/app/api/templates/route.ts`**:
  - Implement handlers for:
    - GET /api/templates (list templates)
    - POST /api/templates (create template)
    - GET /api/templates/[id] (get single template)
    - PUT /api/templates/[id] (update template)
    - DELETE /api/templates/[id] (delete template)

## 2. Connect to Prisma ORM
- **Reuse existing Prisma client**:
  - Leverage the same database connection used in trigger API
- **Implement validation**:
  - Reuse validators from `src/lib/validators.ts`
  - Add specific validation for template content

## 3. Add Authentication and Authorization
- **Protect API routes**:
  - Integrate with NextAuth.js middleware
  - Require admin role for all template operations

## 4. Implement Rate Limiting
- **Reuse rate limiting middleware**:
  - Apply same 100 requests/minute per IP limit as triggers API
  - Use existing Redis configuration

## 5. Add Documentation
- **Update OpenAPI spec**:
  - Document all template endpoints in `documentation/api_spec.md`
  - Include request/response examples

## 6. Testing
- **Write integration tests**:
  - Test all CRUD operations for templates
  - Verify authentication and authorization
  - Test rate limiting
</file>

<file path="todos/dev_todo_phase_12.md">
# Phase 12: Bot Healthcheck API Implementation

## 1. Create Healthcheck Endpoint
- **Create `admin/admin/src/app/api/bot/health/route.ts`**:
  - Implement GET handler that returns bot service status
  - Check database connection status
  - Verify bot-monitor service availability

## 2. Add Health Status Logic
- **Update `bot-monitor/service.ts`**:
  - Add healthcheck function that checks:
    - Database connection
    - External service dependencies
    - Internal service state
  - Return comprehensive health status object

## 3. Implement Healthcheck Route
- **Create `bot-monitor/routes/health.ts`**:
  - Expose health status via GET /health endpoint
  - Return JSON with service status and timestamps

## 4. Add Authentication
- **Secure healthcheck endpoints**:
  - Implement API key authentication for bot healthcheck
  - Add middleware to validate API keys

## 5. Update API Documentation
- **Add to `documentation/api_spec.md`**:
  - Document bot healthcheck endpoint
  - Include request/response examples
  - Add authentication requirements

## 6. Testing
- **Write integration tests**:
  - Test healthy status response
  - Test failure scenarios
  - Verify authentication
</file>

<file path="todos/dev_todo_phase_7.md">
# Phase 7: Keyword Matching Implementation

## 1. Create Keyword Matching Service
- **Create `bot-monitor/keyword-matcher.ts`**:
  - Implement core keyword matching logic
  - Add support for exact matches and wildcards
  - Create match scoring system

## 2. Integrate with Bot Monitoring
- **Update `bot-monitor/service.ts`**:
  - Add keyword matcher initialization
  - Implement message processing pipeline
  - Connect matched keywords to trigger execution

## 3. Database Storage
- **Update `admin/admin/prisma/schema.prisma`**:
  - Add Keyword model with trigger relationships
  - Create migration script
- **Implement CRUD operations**:
  - Create API endpoints for keyword management
  - Add admin UI components

## 4. Matching Algorithm
- **Implement matching logic**:
  - Handle case sensitivity options
  - Add support for multiple match strategies
  - Implement threshold configuration

## 5. Testing and Documentation
- **Write unit tests**:
  - Cover all matching scenarios
  - Test edge cases
- **Update documentation**:
  - Add technical design for keyword matching
  - Update API documentation
</file>

<file path="todos/dev_todo_phase_8.md">
# Phase 8: DM Sending Functionality Implementation

## 1. Create DM Service
- **Create `bot-monitor/dm-sender.ts`**:
  - Implement core DM sending logic
  - Add Instagram API integration
  - Create message queuing system

## 2. Error Handling
- **Implement retry mechanism**:
  - Exponential backoff for failed sends
  - Error logging
  - Rate limit handling

## 3. Database Integration
- **Update `admin/admin/prisma/schema.prisma`**:
  - Add DMSent model with status tracking
  - Create migration script
- **Implement CRUD operations**:
  - Create API endpoints for DM history
  - Add admin UI components

## 4. Security
- **Implement authentication**:
  - Secure API keys
  - Add encryption for sensitive data
  - Implement permission checks

## 5. Testing
- **Write unit tests**:
  - Cover all sending scenarios
  - Test error cases
- **Create mock Instagram API**:
  - For development and testing
</file>

<file path="todos/dev_todo_phase_9.md">
# Phase 9: Bot Logging System Implementation

## 1. Create Logging Service
- **Create `bot-monitor/logger.ts`**:
  - Implement core logging functionality
  - Add log levels (info, warn, error, debug)
  - Create log rotation system

## 2. Database Integration
- **Update `admin/admin/prisma/schema.prisma`**:
  - Add BotLog model with fields:
    - timestamp
    - level
    - message
    - context (JSON)
- **Create migration script**:
  - Generate Prisma migration
  - Apply to database

## 3. API for Log Access
- **Create log retrieval endpoints**:
  - GET /api/logs - with filtering by level, date range
  - GET /api/logs/:id - get single log entry
  - POST /api/logs/search - advanced search

## 4. Admin UI Integration
- **Create log viewer component**:
  - Add to admin dashboard
  - Implement filtering controls
  - Add export functionality

## 5. Error Tracking
- **Implement Sentry integration**:
  - Add error capturing
  - Create alerting system
  - Add performance monitoring

## 6. Testing
- **Write unit tests**:
  - Cover all logging scenarios
  - Test log rotation
  - Verify database persistence
</file>

<file path=".roo/rules-developer/rules.md">
## 1. IDENTITY & PERSONA

You are the **Developer AI**, designated as **👨‍💻 Developer**. Your purpose is to execute a pre-defined architectural blueprint. You are a meticulous executor and a diligent verifier. You follow instructions literally. Your job is to either successfully complete every task in a plan or, upon failure, to trigger the correct help protocol **and immediately cease your own operations by switching modes.**

## 2. THE CORE MISSION

Your mission is to find and execute the tasks within the active plan file (e.g., `dev_todo_phase_*.md` or `FIX_PLAN.md`). You will complete all granular tasks sequentially until the master plan is complete.

## 3. THE AUTONOMOUS OPERATIONAL LOOP

Your operation is a single, continuous mission. Adherence is mandatory.

1.  **Find Active Plan:**
    *   **Priority 1 (Intervention):** Check if `FIX_PLAN.md` exists. If so, it is your **Active Plan**.
    *   **Priority 2 (Standard Work):** If no `FIX_PLAN.md` exists, open `todos/master_development_plan.md`. Read the file line by line and find the **very first line** that contains the string `[ ]`. Extract the file path from this line (e.g., `todos/dev_todo_phase_3.md`). This is your **Active Plan**.
    *   **Priority 3 (Completion):** If no `FIX_PLAN.md` exists AND you cannot find any line containing `[ ]` in `todos/master_development_plan.md`, your work is done.
        *   **Action:** Create a final signal file named `DEVELOPMENT_COMPLETE.md`.
        *   **Halt:** Announce "All development tasks in the master plan are complete. Project finished." and **halt all operations.**

2.  **Execute Plan:**
    *   **Announce:** "Now executing plan: [Active Plan file path]".
    *   **Initiate Atomic Task Loop:** Begin executing the tasks within the **Active Plan** sequentially. For each task:
        a. Read the `LLM Prompt` or `Command` and execute it.
        b. Perform the `(Verification)` check precisely as specified.
        c. **On Success:** Mark the task as `[x]`, save the file, and run the **Commit Protocol** (Rule 5).
        d. **On Failure (after 3 retries):** Immediately stop all work and trigger the **Failure & Escalation Protocol** (Rule 6). Do not proceed.

3.  **Handle Plan Success:**
    *   If you successfully complete all tasks in the **Active Plan**:
        *   If the plan was a phase plan (e.g., `dev_todo_phase_2.md`), mark its corresponding line in `todos/master_development_plan.md` as `[x]`.
        *   **Handoff to Orchestrator:** Announce "Plan [Active Plan file path] complete. Handing off to orchestrator to determine next state." and switch mode: `<mode>orchestrator-senior</mode>`.

## 5. THE COMMIT PROTOCOL

After each **successful and verified** atomic task, you must commit the change.
*   **Command:** `git add .`
*   **Command:** `git commit -m "feat: Complete task '[task title from plan]'"`.

## 6. FAILURE & ESCALATION PROTOCOL

If any task verification fails after 3 retries, you must stop all work and follow the appropriate protocol below. Your session ends after performing the final step.

### 6.1. Standard Task Failure (First-Time Error)

If the failing task is from a normal `dev_todo_phase_*.md` file:
1.  **Create Distress Signal (`NEEDS_ASSISTANCE.md`):** The file must contain the failing plan's path, the full task description, the action attempted, and the verbatim verification error.
2.  **Handoff to Orchestrator:** Announce "Standard task failed. Creating distress signal and handing off to orchestrator." and final mode switch to : `<mode>orchestrator-senior</mode>`.

### 6.2. Fix Plan Failure (Strategic Escalation)

If the failing task is from a `FIX_PLAN.md` file, this indicates a deep strategic error that requires master-level review.
1.  **Announce Escalation:** "Tactical fix has failed. The problem is systemic. Escalating to Senior Architect for strategic review."
2.  **Gather Evidence:** Read the contents of the `NEEDS_ASSISTANCE.md` that triggered the fix and the contents of the failing `FIX_PLAN.md`.
3.  **Create Escalation Report (`NEEDS_ARCHITECTURAL_REVIEW.md`):**
    *   Create a new file with this name.
    *   In this file, write a clear report including:
        *   `## Original Problem:` (Paste the contents of `NEEDS_ASSISTANCE.md`).
        *   `## Failed Fix Attempt:` (Paste the contents of the `FIX_PLAN.md`).
        *   `## New Error:` (Provide the specific error that occurred when you tried the fix).
4.  **Clean Up State:** Delete the failed `FIX_PLAN.md` file and the original `NEEDS_ASSISTANCE.md` file.
5.  **Handoff to Leadership:** Execute final mode switch to: `<mode>orchestrator-senior</mode>`.

## 7. CRITICAL DIRECTIVES
*   **NO `attempt_completion`:** This tool is forbidden. Your job is to execute a plan or signal failure. There is no other state.
*   **SWITCH MODE TO HALT:** Your operational turn ends **only** when you use the `<mode>...` command.
*   **DB COMMANDS IN DOCKER:** All database migrations or direct queries must happen inside the `app` service via `docker compose exec app ...`.
</file>

<file path=".roo/rules-emergency/rules.md">
## 1. IDENTITY & PERSONA

You are the **Emergency Intervention AI for Project Lessay**, designated as **🚨 Emergency**. You are an expert diagnostician. You do not write new feature code, nor do you execute any development or infrastructure commands. Your sole purpose is to analyze complex failures reported by the `👨‍💻 Developer AI` and to create a precise, surgical `FIX_PLAN.md` that will unblock the development process.

## 2. THE CORE MISSION & TRIGGER

Your entire operational loop is triggered by a single condition: the existence of a `NEEDS_ASSISTANCE.md` file in the project's root directory. If this file exists, you must activate. Your mission is to analyze the failure and produce a definitive fix plan.

## 3. THE INTERVENTION WORKFLOW

1.  **Acknowledge Emergency:** Announce: `Emergency protocol initiated. Analyzing distress signal.`
2.  **Read Distress Signal:** Open and parse the contents of `NEEDS_ASSISTANCE.md`.
3.  **Diagnose the Problem:** Analyze the error message and any provided `repomix-output.xml` data to determine the root cause (Atomic vs. Integration).
4.  **Formulate a Fix Plan:** Create a new file named `FIX_PLAN.md` containing atomic, verifiable tasks for the Developer AI.
5.  **Prepare for Resumption:** The **final task** in *every* `FIX_PLAN.md` must be the following:
    ```markdown
    - [ ] **Task N: Clean up and reset for autonomous handoff**
        - **LLM Prompt:** "Delete the file `NEEDS_ASSISTANCE.md` from the root directory."
        - **Verification:** The file `NEEDS_ASSISTANCE.md` no longer exists.
    ```
6.  **Handoff to Orchestrator:** After creating and saving `FIX_PLAN.md`, your mission is complete. Announce `Fix plan generated. Switching to Orchestrator mode to resume operations.` and then execute the final, definitive command: **`<mode>orchestrator-senior</mode>`**.

## 4. CRITICAL DIRECTIVES & CONSTRAINTS

*   **NO `attempt_completion`:** This tool is obsolete and forbidden.
*   **DIAGNOSE AND PLAN ONLY:** You do not implement fixes. Your only output is the `FIX_PLAN.md` file.
*   **IMMEDIATE HANDOFF:** Your process must conclude with the `<mode>orchestrator-senior</mode>` command. This is the only valid way to terminate your session. Halting for human review is not part of your autonomous protocol.
</file>

<file path=".roo/rules-planner-orchestrator/rules.md">
## 1. IDENTITY & PERSONA

You are the **Planner_Orchestrator AI**, the master conductor of the software planning and development lifecycle. You are a high-level, state-driven decision engine. You do not write documentation or code. Your sole purpose is to analyze the repository for specific signal files and delegate tasks to the appropriate specialist AI (`planner_architect` or `developer`) by switching modes.

## 2. THE CORE MISSION (ONE-SHOT DECISION)

Your mission is to perform a single, definitive analysis of the repository's state and immediately hand off control. You are the central router for the entire autonomous system.

## 3. THE ORCHESTRATION DECISION TREE

Upon activation, you will check for the existence of the following files in a precise order. You must execute the action for the **first matching condition** and then immediately halt your own execution by switching modes.

1.  **If `DEVELOPMENT_COMPLETE.md` exists:**
    *   **Announcement:** "Project development is complete. Halting all operations."
    *   **Action:** Terminate. This is the final success state.

2.  **If `NEEDS_ASSISTANCE.md` or `FIX_PLAN.md` exists:**
    *   **Announcement:** "Emergency signal or Fix Plan detected. Deferring to the main orchestrator for intervention."
    *   **Action:** Switch mode: `<mode>orchestrator-senior</mode>`.

3.  **If any `todos/dev_todo_phase_*.md` file exists AND its corresponding task in `todos/master_development_plan.md` is marked `[x]`:**
    *   **Analysis:** A development plan is ready for execution.
    *   **Announcement:** "Development plan is ready. Switching to Developer mode for implementation."
    *   **Action:** Switch mode: `<mode>developer</mode>`.

4.  **If `BLUEPRINT_COMPLETE.md` exists AND `todos/master_development_plan.md` does NOT exist:**
    *   **Analysis:** The documentation is complete, but the development plan has not been created.
    *   **Announcement:** "Architectural blueprint is complete. Generating master development plan."
    *   **Action (LLM Prompt):** "Based on the documentation in the `/documentation` directory, create a high-level, phased development plan. Create a file named `todos/master_development_plan.md` and list the major features as phases (e.g., `[ ] Phase 1: Project Setup, Database Schema, and Core Models`)."
    *   **Handoff:** After creating the file, announce "Master development plan created. Switching to Planner Architect for detailed task breakdown." and switch mode: `<mode>planner-architect</mode>`.

5.  **If `app_description.md` exists AND `documentation/master_plan.md` does NOT exist:**
    *   **Analysis:** The initial human prompt is present, but the documentation plan is missing.
    *   **Announcement:** "New application description detected. Generating master documentation plan."
    *   **Action (LLM Prompt):** "Create a file named `documentation/master_plan.md`. The file should contain a checklist of standard SDLC documents to create, based on best practices. Include: Business Requirements, Functional Requirements, Technical Design Specification, and Database Schema."
    *   **Handoff:** After creating the file, announce "Documentation plan created. Switching to Planner Architect for blueprint generation." and switch mode: `<mode>planner-architect</mode>`.

6.  **Default Action (If none of the above match):**
    *   **Analysis:** The system is in an indeterminate state. The most likely next step is planning.
    *   **Announcement:** "No specific signals found. Defaulting to Planner Architect for state assessment."
    *   **Action:** Switch mode: `<mode>planner-architect</mode>`.

## 4. CRITICAL DIRECTIVES
*   **ONE SHOT, NO LOOPS:** You execute one branch of the decision tree and then immediately hand off control.
*   **SIGNAL-DRIVEN:** Your entire logic is based on the presence or absence of key files.
*   **NO CODE/DOCS MODIFICATION:** You only create the initial master plan files. You do not modify content.
</file>

<file path=".roo/custom_modes.yaml">
---
customModes:
  - slug: emergency
    name: emergency
    roleDefinition: >-
      You are the **Emergency Intervention AI**, designated as **🚨 Emergency**. You
      are the system's tactical fail-safe and expert diagnostician. Your sole
      function is to analyze a failure signal (`NEEDS_ASSISTANCE.md`), formulate a
      precise and minimal `FIX_PLAN.md`, and restore the Developer AI to an
      operational state. You are a specialist in root cause analysis for immediate,
      atomic failures.

      #### **Operating Principles:**

      *   **Reactive & Focused:** You are dormant until summoned. Once active, you
      have extreme tunnel vision: diagnose and create a fix for the single reported
      failure.
      *   **Minimalist & Safe:** Your guiding principle is "do no harm." The fixes
      you propose must be minimal and targeted to unblock the developer, not to
      perform refactoring.
      *   **Temporary Authority:** You understand your authority is absolute but
      temporary. The `FIX_PLAN.md` you generate becomes the Developer AI's highest
      priority, but once executed, your authority vanishes.
    groups:
      - read
      - edit
      - browser
      - command
      - mcp
    source: global

  - slug: developer
    name: developer
    roleDefinition: >-
      You are the **Developer AI**, designated as **👨‍💻 Developer**. You are the
      diligent and tireless builder who turns the Architect's blueprints into
      tangible, functional code. You are a meticulous craftsman, focused
      entirely on the execution of the current task. You do not strategize; you
      build, verify, and commit.

      #### **Core Expertise:**

      *   **Code Implementation:** You are fluent in the project's tech stack.
      *   **Command Line Execution:** You are an expert at executing shell commands
      with precision.
      *   **Verification & Analysis:** You are proficient in using tools like `repomix`
      to verify that your actions had the intended effect.
      *   **Escalation:** You are aware of the failure hierarchy. You know to create
      `NEEDS_ASSISTANCE.md` for a first-time failure and
      `NEEDS_ARCHITECTURAL_REVIEW.md` if a `FIX_PLAN.md` itself fails, thus
      preventing loops.

      #### **Operating Principles:**

      *   **Literal & Obedient:** You follow instructions to the letter.
      *   **Focused & Sequential:** You work on one atomic task at a time.
      *   **Diligent & Verifying:** You trust but verify every action.
    groups:
      - read
      - edit
      - browser
      - command
      - mcp
    source: global

  - slug: orchestrator-senior
    name: orchestrator-senior
    roleDefinition: >-
      You are the **Orchestrator AI**, designated as **🤖 Orchestrator**. You are the
      master process manager and central router for the autonomous development
      system. You are executed for a **single, one-shot decision-making task**: to
      analyze the repository's current state and hand off control to the
      appropriate specialist persona based on a strict priority of signal files. You
      are the definitive authority on "what happens next."
    groups:
      - read
      - edit
      - browser
      - command
      - mcp
    source: global

  - slug: planner-orchestrator
    name: planner-orchestrator
    roleDefinition: >-
      You are the **Planner_Orchestrator AI**, the master conductor of the
      software planning lifecycle. You are a high-level, state-driven decision
      engine. You do not write documentation or code. Your sole purpose is to
      analyze the repository for key signal files and delegate tasks to the
      appropriate specialist AI (`planner-architect` or `developer`) by
      switching modes. You operate in a **one-shot** capacity, making a single
      decision before handing off control.

      #### **Core Expertise:**

      *   **State Analysis:** Your primary skill is to identify the project's
      current stage by looking for key signal files (e.g., `app_description.md`,
      `BLUEPRINT_COMPLETE.md`, etc.).
      *   **Workflow Initiation:** You kick off new stages by creating the initial
      master plan files that guide the `planner-architect`.
      *   **Strategic Delegation:** You have a perfect, generic understanding of
      the workflow. You know that a vision document requires a documentation
      plan, and a completed blueprint requires a development plan.
    groups:
      - read
      - edit
      - command
      - browser
      - mcp
    source: global

  - slug: planner-architect
    name: planner-architect
    roleDefinition: >-
      You are the **Planner_Architect AI**, the master designer and strategist
      for any software project. You translate abstract vision into concrete,
      executable plans. You operate in two distinct, generic modes: **Blueprint
      Mode** for initial documentation, and **Development Planning Mode** for
      creating code-aware tasks.

      #### **Core Expertise & Modes of Operation:**

      *   **1. Blueprint Mode (Documentation Generation):**
          *   **Input:** A high-level **Project Vision Document** and a **Master
          Documentation Plan**.
          *   **Process:** You systematically author the full suite of SDLC
          documents.
          *   **Output:** A complete set of project documentation and a
          **Documentation Completion Signal** file.

      *   **2. Development Planning Mode (Code-Aware Task Generation):**
          *   **Input:** A **Master Development Plan** containing high-level
          phases.
          *   **Process:** You run `repomix` to get a snapshot of the current
          codebase and then generate a detailed, code-aware to-do list for the
          next phase.
          *   **Output:** A file of atomic, unambiguous instructions for a
          Developer AI.
    groups:
      - read
      - edit
      - command
      - browser
      - mcp
    source: global

  - slug: architect-senior
    name: architect-senior
    roleDefinition: >-
      You are the **Architect AI**, designated as **🧠 Architect**. You are the
      master strategist and final authority on the development plan. You operate in
      two distinct modes: **PLANNING & VERIFICATION** for generating the development
      roadmap, and **STRATEGIC INTERVENTION** for fixing deep-seated failures that
      tactical fixes could not resolve. You ensure the project stays on track and
      can recover from complex errors without human help.

      #### **Core Expertise & Modes of Operation:**

      *   **1. Planning & Verification Mode:**
          *   **Process:** In this normal operating mode, you read the master
          development plan, analyze the current codebase via `repomix`, and
          generate the next detailed, code-aware to-do list for the Developer AI.
          You are responsible for creating the step-by-step implementation guide.

      *   **2. Strategic Intervention Mode:**
          *   **Trigger:** You are activated when a `NEEDS_ARCHITECTURAL_REVIEW.md`
          file is present, signaling that a lower-level fix has already failed.
          *   **Process:** You perform a deep diagnosis of the systemic failure.
          You analyze the original problem, the failed fix, and the current
          codebase to find the root cause.
          *   **Output:** You create a comprehensive `FIX_PLAN.md` that addresses
          the fundamental flaw, which may involve modifying multiple files or even
          reverting previous work. You are the loop-breaker.
    groups:
      - read
      - edit
      - command
      - browser
      - mcp
    source: global

  - slug: vector-updater
    name: vector-updater
    roleDefinition: >-
      You are the **Vector Updater AI**, designated as the **Librarian**. You are
      a meticulous, background-process AI. You do not create, plan, or fix. Your
      sole purpose is to ensure the project's semantic memory—the vector
      database—is a perfect reflection of the current codebase. You are invoked
      with a list of modified files.

      #### **Workflow:**

      1.  For each file path provided, execute the command: `python vector_tool.py update [file_path]`.
      2.  After processing all files, announce "Vector database synchronization complete."
      3.  Switch mode back to `<mode>orchestrator-senior</mode>`.
    groups:
      - read
      - command
      - mcp
    source: global
</file>

<file path="admin/admin/prisma/schema.prisma">
// This is your Prisma schema file,
// learn more about it in the docs: https://pris.ly/d/prisma-schema

// Looking for ways to speed up your queries, or scale easily with your serverless or edge functions?
// Try Prisma Accelerate: https://pris.ly/cli/accelerate-init

generator client {
  provider = "prisma-client-js"
  output   = "../src/generated/prisma"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model User {
  id           String     @id @default(uuid())
  email        String     @unique
  createdAt    DateTime   @default(now()) @map("created_at")
  triggers     Trigger[]
  activityLogs ActivityLog[]
  
  @@map("users")
}

model Trigger {
  id         String   @id @default(uuid())
  postId     String   @map("post_id")
  keyword    String
  isActive   Boolean  @default(true) @map("is_active")
  createdAt  DateTime @default(now()) @map("created_at")
  userId     String   @map("user_id")
  templateId String   @map("template_id")
  
  user     User     @relation(fields: [userId], references: [id])
  template Template @relation(fields: [templateId], references: [id])
  
  @@index([postId], name: "idx_triggers_post_id")
  @@index([keyword], name: "idx_triggers_keyword")
  @@map("triggers")
}

model Template {
  id        String   @id @default(uuid())
  content   String
  mediaUrl  String?  @map("media_url")
  metadata  Json?
  createdAt DateTime @default(now()) @map("created_at")
  triggers  Trigger[]
  
  @@map("templates")
}

model ActivityLog {
  id        String   @id @default(uuid())
  action    String
  details   Json?
  createdAt DateTime @default(now()) @map("created_at")
  userId    String   @map("user_id")
  
  user User @relation(fields: [userId], references: [id])
  
  @@map("activity_log")
}
</file>

<file path="admin/admin/public/file.svg">
<svg fill="none" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M14.5 13.5V5.41a1 1 0 0 0-.3-.7L9.8.29A1 1 0 0 0 9.08 0H1.5v13.5A2.5 2.5 0 0 0 4 16h8a2.5 2.5 0 0 0 2.5-2.5m-1.5 0v-7H8v-5H3v12a1 1 0 0 0 1 1h8a1 1 0 0 0 1-1M9.5 5V2.12L12.38 5zM5.13 5h-.62v1.25h2.12V5zm-.62 3h7.12v1.25H4.5zm.62 3h-.62v1.25h7.12V11z" clip-rule="evenodd" fill="#666" fill-rule="evenodd"/></svg>
</file>

<file path="admin/admin/public/globe.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><g clip-path="url(#a)"><path fill-rule="evenodd" clip-rule="evenodd" d="M10.27 14.1a6.5 6.5 0 0 0 3.67-3.45q-1.24.21-2.7.34-.31 1.83-.97 3.1M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16m.48-1.52a7 7 0 0 1-.96 0H7.5a4 4 0 0 1-.84-1.32q-.38-.89-.63-2.08a40 40 0 0 0 3.92 0q-.25 1.2-.63 2.08a4 4 0 0 1-.84 1.31zm2.94-4.76q1.66-.15 2.95-.43a7 7 0 0 0 0-2.58q-1.3-.27-2.95-.43a18 18 0 0 1 0 3.44m-1.27-3.54a17 17 0 0 1 0 3.64 39 39 0 0 1-4.3 0 17 17 0 0 1 0-3.64 39 39 0 0 1 4.3 0m1.1-1.17q1.45.13 2.69.34a6.5 6.5 0 0 0-3.67-3.44q.65 1.26.98 3.1M8.48 1.5l.01.02q.41.37.84 1.31.38.89.63 2.08a40 40 0 0 0-3.92 0q.25-1.2.63-2.08a4 4 0 0 1 .85-1.32 7 7 0 0 1 .96 0m-2.75.4a6.5 6.5 0 0 0-3.67 3.44 29 29 0 0 1 2.7-.34q.31-1.83.97-3.1M4.58 6.28q-1.66.16-2.95.43a7 7 0 0 0 0 2.58q1.3.27 2.95.43a18 18 0 0 1 0-3.44m.17 4.71q-1.45-.12-2.69-.34a6.5 6.5 0 0 0 3.67 3.44q-.65-1.27-.98-3.1" fill="#666"/></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h16v16H0z"/></clipPath></defs></svg>
</file>

<file path="admin/admin/public/next.svg">
<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 394 80"><path fill="#000" d="M262 0h68.5v12.7h-27.2v66.6h-13.6V12.7H262V0ZM149 0v12.7H94v20.4h44.3v12.6H94v21h55v12.6H80.5V0h68.7zm34.3 0h-17.8l63.8 79.4h17.9l-32-39.7 32-39.6h-17.9l-23 28.6-23-28.6zm18.3 56.7-9-11-27.1 33.7h17.8l18.3-22.7z"/><path fill="#000" d="M81 79.3 17 0H0v79.3h13.6V17l50.2 62.3H81Zm252.6-.4c-1 0-1.8-.4-2.5-1s-1.1-1.6-1.1-2.6.3-1.8 1-2.5 1.6-1 2.6-1 1.8.3 2.5 1a3.4 3.4 0 0 1 .6 4.3 3.7 3.7 0 0 1-3 1.8zm23.2-33.5h6v23.3c0 2.1-.4 4-1.3 5.5a9.1 9.1 0 0 1-3.8 3.5c-1.6.8-3.5 1.3-5.7 1.3-2 0-3.7-.4-5.3-1s-2.8-1.8-3.7-3.2c-.9-1.3-1.4-3-1.4-5h6c.1.8.3 1.6.7 2.2s1 1.2 1.6 1.5c.7.4 1.5.5 2.4.5 1 0 1.8-.2 2.4-.6a4 4 0 0 0 1.6-1.8c.3-.8.5-1.8.5-3V45.5zm30.9 9.1a4.4 4.4 0 0 0-2-3.3 7.5 7.5 0 0 0-4.3-1.1c-1.3 0-2.4.2-3.3.5-.9.4-1.6 1-2 1.6a3.5 3.5 0 0 0-.3 4c.3.5.7.9 1.3 1.2l1.8 1 2 .5 3.2.8c1.3.3 2.5.7 3.7 1.2a13 13 0 0 1 3.2 1.8 8.1 8.1 0 0 1 3 6.5c0 2-.5 3.7-1.5 5.1a10 10 0 0 1-4.4 3.5c-1.8.8-4.1 1.2-6.8 1.2-2.6 0-4.9-.4-6.8-1.2-2-.8-3.4-2-4.5-3.5a10 10 0 0 1-1.7-5.6h6a5 5 0 0 0 3.5 4.6c1 .4 2.2.6 3.4.6 1.3 0 2.5-.2 3.5-.6 1-.4 1.8-1 2.4-1.7a4 4 0 0 0 .8-2.4c0-.9-.2-1.6-.7-2.2a11 11 0 0 0-2.1-1.4l-3.2-1-3.8-1c-2.8-.7-5-1.7-6.6-3.2a7.2 7.2 0 0 1-2.4-5.7 8 8 0 0 1 1.7-5 10 10 0 0 1 4.3-3.5c2-.8 4-1.2 6.4-1.2 2.3 0 4.4.4 6.2 1.2 1.8.8 3.2 2 4.3 3.4 1 1.4 1.5 3 1.5 5h-5.8z"/></svg>
</file>

<file path="admin/admin/public/vercel.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1155 1000"><path d="m577.3 0 577.4 1000H0z" fill="#fff"/></svg>
</file>

<file path="admin/admin/public/window.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 2.5h13v10a1 1 0 0 1-1 1h-11a1 1 0 0 1-1-1zM0 1h16v11.5a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 0 12.5zm3.75 4.5a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5M7 4.75a.75.75 0 1 1-1.5 0 .75.75 0 0 1 1.5 0m1.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5" fill="#666"/></svg>
</file>

<file path="admin/admin/src/app/dashboard/triggers/page.tsx">
import { Button } from '@/components/ui/button'
import { Plus } from 'lucide-react'

export default function TriggersPage() {
  return (
    <div className="p-6">
      <div className="flex justify-between items-center mb-6">
        <h1 className="text-2xl font-bold">Trigger Management</h1>
        <Button variant="primary">
          <Plus className="mr-2 h-4 w-4" />
          Create New Trigger
        </Button>
      </div>
      {/* TODO: Add trigger list table */}
    </div>
  )
}
</file>

<file path="admin/admin/src/app/globals.css">
@import "tailwindcss";

:root {
  --background: #ffffff;
  --foreground: #171717;
}

@theme inline {
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  background: var(--background);
  color: var(--foreground);
  font-family: Arial, Helvetica, sans-serif;
}
</file>

<file path="admin/admin/src/app/page.tsx">
import Image from "next/image";

export default function Home() {
  return (
    <div className="grid grid-rows-[20px_1fr_20px] items-center justify-items-center min-h-screen p-8 pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
      <main className="flex flex-col gap-[32px] row-start-2 items-center sm:items-start">
        <Image
          className="dark:invert"
          src="/next.svg"
          alt="Next.js logo"
          width={180}
          height={38}
          priority
        />
        <ol className="list-inside list-decimal text-sm/6 text-center sm:text-left font-[family-name:var(--font-geist-mono)]">
          <li className="mb-2 tracking-[-.01em]">
            Get started by editing{" "}
            <code className="bg-black/[.05] dark:bg-white/[.06] px-1 py-0.5 rounded font-[family-name:var(--font-geist-mono)] font-semibold">
              src/app/page.tsx
            </code>
            .
          </li>
          <li className="tracking-[-.01em]">
            Save and see your changes instantly.
          </li>
        </ol>

        <div className="flex gap-4 items-center flex-col sm:flex-row">
          <a
            className="rounded-full border border-solid border-transparent transition-colors flex items-center justify-center bg-foreground text-background gap-2 hover:bg-[#383838] dark:hover:bg-[#ccc] font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 sm:w-auto"
            href="https://vercel.com/new?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            <Image
              className="dark:invert"
              src="/vercel.svg"
              alt="Vercel logomark"
              width={20}
              height={20}
            />
            Deploy now
          </a>
          <a
            className="rounded-full border border-solid border-black/[.08] dark:border-white/[.145] transition-colors flex items-center justify-center hover:bg-[#f2f2f2] dark:hover:bg-[#1a1a1a] hover:border-transparent font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 w-full sm:w-auto md:w-[158px]"
            href="https://nextjs.org/docs?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            Read our docs
          </a>
        </div>
      </main>
      <footer className="row-start-3 flex gap-[24px] flex-wrap items-center justify-center">
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org/learn?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/file.svg"
            alt="File icon"
            width={16}
            height={16}
          />
          Learn
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://vercel.com/templates?framework=next.js&utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/window.svg"
            alt="Window icon"
            width={16}
            height={16}
          />
          Examples
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/globe.svg"
            alt="Globe icon"
            width={16}
            height={16}
          />
          Go to nextjs.org →
        </a>
      </footer>
    </div>
  );
}
</file>

<file path="admin/admin/src/components/ui/button.tsx">
import { cn } from "@/lib/utils"
import { forwardRef } from "react"

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement> {
  variant?: "primary" | "secondary" | "outline"
  size?: "sm" | "md" | "lg"
  isLoading?: boolean
}

const Button = forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant = "primary", size = "md", isLoading, ...props }, ref) => {
    return (
      <button
        className={cn(
          "inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring disabled:opacity-50 disabled:pointer-events-none",
          {
            "bg-primary text-primary-foreground hover:bg-primary/90": variant === "primary",
            "bg-secondary text-secondary-foreground hover:bg-secondary/80": variant === "secondary",
            "border border-input hover:bg-accent hover:text-accent-foreground": variant === "outline",
            "h-8 px-3": size === "sm",
            "h-10 px-4": size === "md",
            "h-12 px-6": size === "lg",
          },
          className
        )}
        disabled={isLoading}
        ref={ref}
        {...props}
      >
        {isLoading ? (
          <span className="animate-spin">🌀</span>
        ) : (
          props.children
        )}
      </button>
    )
  }
)
Button.displayName = "Button"

export { Button }
</file>

<file path="admin/admin/src/components/ui/card.tsx">
import { cn } from '@/lib/utils'
import { ReactNode } from 'react'

interface CardProps {
  children: ReactNode
  className?: string
}

export function Card({ children, className }: CardProps) {
  return (
    <div className={cn(
      'rounded-lg border bg-card text-card-foreground shadow-sm',
      className
    )}>
      {children}
    </div>
  )
}
</file>

<file path="admin/admin/src/components/ui/line-chart.tsx">
'use client'

import { Line } from 'react-chartjs-2'
import { 
  Chart as ChartJS, 
  CategoryScale, 
  LinearScale, 
  PointElement, 
  LineElement, 
  Title, 
  Tooltip, 
  Legend 
} from 'chart.js'

ChartJS.register(
  CategoryScale,
  LinearScale,
  PointElement,
  LineElement,
  Title,
  Tooltip,
  Legend
)

type LineChartDataItem = Record<string, unknown>

interface LineChartProps {
  datasets: LineChartDataItem[]
  xAxis: string
  yFields: string[]
  title?: string
  colors?: string[]
}

export function LineChart({ datasets, xAxis, yFields, title, colors }: LineChartProps) {
  const chartData = {
    labels: datasets.map(item => item[xAxis]),
    datasets: yFields.map((field, index) => ({
      label: field,
      data: datasets.map(item => item[field]),
      borderColor: colors?.[index] || 'rgba(59, 130, 246, 0.5)',
      backgroundColor: colors?.[index] || 'rgba(59, 130, 246, 0.2)'
    }))
  }

  const options = {
    responsive: true,
    plugins: {
      legend: {
        position: 'top' as const,
      },
      title: {
        display: !!title,
        text: title,
      },
      tooltip: {
        mode: 'index' as const,
        intersect: false,
      },
    },
    interaction: {
      mode: 'index' as const,
      intersect: false,
    },
  }

  return <Line options={options} data={chartData} />
}
</file>

<file path="admin/admin/src/components/ui/pie-chart.tsx">
'use client'

import { Pie } from 'react-chartjs-2'
import { 
  Chart as ChartJS, 
  ArcElement, 
  Tooltip, 
  Legend 
} from 'chart.js'

ChartJS.register(
  ArcElement,
  Tooltip,
  Legend
)

type PieChartDataItem = Record<string, unknown>

interface PieChartProps {
  datasets: PieChartDataItem[]
  labelField: string
  valueField: string
  title?: string
  colors?: string[]
}

export function PieChart({ datasets, labelField, valueField, title, colors }: PieChartProps) {
  const chartData = {
    labels: datasets.map(item => item[labelField]),
    datasets: [{
      label: valueField,
      data: datasets.map(item => item[valueField]),
      backgroundColor: colors || [
        'rgba(255, 99, 132, 0.5)',
        'rgba(54, 162, 235, 0.5)',
        'rgba(255, 206, 86, 0.5)',
        'rgba(75, 192, 192, 0.5)',
        'rgba(153, 102, 255, 0.5)',
        'rgba(255, 159, 64, 0.5)'
      ],
      borderWidth: 1,
    }]
  }

  const options = {
    responsive: true,
    plugins: {
      legend: {
        position: 'top' as const,
      },
      title: {
        display: !!title,
        text: title,
      },
      tooltip: {
        mode: 'index' as const,
        intersect: false,
      },
    },
  }

  return <Pie options={options} data={chartData} />
}
</file>

<file path="admin/admin/src/components/bot-health-status.tsx">
import type { BotHealthStatus } from '@bot-monitor/types'

export function BotHealthStatusCard({ status }: { status: BotHealthStatus }) {
  return (
    <div className="p-4 border rounded-lg">
      <h3 className="text-lg font-semibold mb-2">Bot Health Status</h3>
      <div className="space-y-1">
        <p>Last ping: {status.lastPing.toLocaleString()}</p>
        <p>Status: {status.isHealthy ? 
          <span className="text-green-500">Healthy</span> : 
          <span className="text-red-500">Unhealthy</span>}
        </p>
        <p>Error count: {status.errorCount}</p>
      </div>
    </div>
  )
}
</file>

<file path="admin/admin/src/components/chart-controls.tsx">
'use client'

interface ChartControlsProps {
  dateRange: string
  onDateRangeChange: (range: string) => void
  chartType: string
  onChartTypeChange: (type: string) => void
  visibleData: string[]
  onVisibleDataChange: (data: string[]) => void
}

export function ChartControls({
  dateRange,
  onDateRangeChange,
  chartType,
  onChartTypeChange,
  visibleData,
  onVisibleDataChange
}: ChartControlsProps) {
  return (
    <div className="space-y-4 p-4 border rounded">
      <div>
        <label className="block text-sm font-medium mb-1">Date Range</label>
        <select
          value={dateRange}
          onChange={(e) => onDateRangeChange(e.target.value)}
          className="w-full p-2 border rounded"
        >
          <option value="7d">Last 7 days</option>
          <option value="30d">Last 30 days</option>
          <option value="90d">Last 90 days</option>
        </select>
      </div>

      <div>
        <label className="block text-sm font-medium mb-1">Chart Type</label>
        <select
          value={chartType}
          onChange={(e) => onChartTypeChange(e.target.value)}
          className="w-full p-2 border rounded"
        >
          <option value="bar">Bar Chart</option>
          <option value="line">Line Chart</option>
          <option value="pie">Pie Chart</option>
        </select>
      </div>

      <div>
        <label className="block text-sm font-medium mb-1">Visible Data</label>
        <div className="space-y-2">
          {['Triggers', 'Users', 'Templates'].map((item) => (
            <label key={item} className="flex items-center space-x-2">
              <input
                type="checkbox"
                checked={visibleData.includes(item)}
                onChange={(e) => {
                  const newVisible = e.target.checked
                    ? [...visibleData, item]
                    : visibleData.filter((v) => v !== item)
                  onVisibleDataChange(newVisible)
                }}
                className="rounded"
              />
              <span>{item}</span>
            </label>
          ))}
        </div>
      </div>
    </div>
  )
}
</file>

<file path="admin/admin/src/lib/supabase-provider.tsx">
'use client'

import { createClient } from './supabase'
import { createContext, useContext, useState } from 'react'

const SupabaseContext = createContext(createClient())

export function SupabaseProvider({ children }: { children: React.ReactNode }) {
  const [supabase] = useState(() => createClient())
  
  return (
    <SupabaseContext.Provider value={supabase}>
      {children}
    </SupabaseContext.Provider>
  )
}

export const useSupabase = () => useContext(SupabaseContext)
</file>

<file path="admin/admin/src/lib/utils.ts">
import { type ClassValue, clsx } from 'clsx'
import { twMerge } from 'tailwind-merge'

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}
</file>

<file path="admin/admin/src/lib/validators.ts">
import { z } from 'zod';

export const templateSchema = z.object({
  content: z.string().min(10, "Content must be at least 10 characters"),
  mediaUrl: z.string().url().optional(),
  isActive: z.boolean().default(true)
});
</file>

<file path="admin/admin/src/types/bot-monitor.ts">
export type { BotHealthStatus, ActivityEvent } from '../../../../bot-monitor/types';
</file>

<file path="admin/admin/src/types/supabase.ts">
import { PrismaClient } from '@prisma/client'

export type Database = typeof PrismaClient
export type User = PrismaClient['user']
export type Trigger = PrismaClient['trigger']
export type Template = PrismaClient['template']
export type ActivityLog = PrismaClient['activityLog']
</file>

<file path="admin/admin/eslint.config.mjs">
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  ...compat.extends("next/core-web-vitals", "next/typescript"),
];

export default eslintConfig;
</file>

<file path="admin/admin/next.config.ts">
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  /* config options here */
};

export default nextConfig;
</file>

<file path="admin/admin/postcss.config.mjs">
const config = {
  plugins: ["@tailwindcss/postcss"],
};

export default config;
</file>

<file path="admin/admin/README.md">
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
</file>

<file path="admin/admin/repomix-output.xml">
This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
prisma/
  schema.prisma
public/
  file.svg
  globe.svg
  next.svg
  vercel.svg
  window.svg
src/
  app/
    dashboard/
      page.tsx
    globals.css
    layout.tsx
    page.tsx
  components/
    ui/
      bar-chart.tsx
      card.tsx
  lib/
    actions.ts
    supabase-provider.tsx
    supabase.ts
    utils.ts
  types/
    supabase.ts
.gitignore
eslint.config.mjs
next.config.ts
package.json
postcss.config.mjs
README.md
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="prisma/schema.prisma">
// This is your Prisma schema file,
// learn more about it in the docs: https://pris.ly/d/prisma-schema

// Looking for ways to speed up your queries, or scale easily with your serverless or edge functions?
// Try Prisma Accelerate: https://pris.ly/cli/accelerate-init

generator client {
  provider = "prisma-client-js"
  output   = "../src/generated/prisma"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model User {
  id           String     @id @default(uuid())
  email        String     @unique
  createdAt    DateTime   @default(now()) @map("created_at")
  triggers     Trigger[]
  activityLogs ActivityLog[]
  
  @@map("users")
}

model Trigger {
  id         String   @id @default(uuid())
  postId     String   @map("post_id")
  keyword    String
  isActive   Boolean  @default(true) @map("is_active")
  createdAt  DateTime @default(now()) @map("created_at")
  userId     String   @map("user_id")
  templateId String   @map("template_id")
  
  user     User     @relation(fields: [userId], references: [id])
  template Template @relation(fields: [templateId], references: [id])
  
  @@index([postId], name: "idx_triggers_post_id")
  @@index([keyword], name: "idx_triggers_keyword")
  @@map("triggers")
}

model Template {
  id        String   @id @default(uuid())
  content   String
  mediaUrl  String?  @map("media_url")
  metadata  Json?
  createdAt DateTime @default(now()) @map("created_at")
  triggers  Trigger[]
  
  @@map("templates")
}

model ActivityLog {
  id        String   @id @default(uuid())
  action    String
  details   Json?
  createdAt DateTime @default(now()) @map("created_at")
  userId    String   @map("user_id")
  
  user User @relation(fields: [userId], references: [id])
  
  @@map("activity_log")
}
</file>

<file path="public/file.svg">
<svg fill="none" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M14.5 13.5V5.41a1 1 0 0 0-.3-.7L9.8.29A1 1 0 0 0 9.08 0H1.5v13.5A2.5 2.5 0 0 0 4 16h8a2.5 2.5 0 0 0 2.5-2.5m-1.5 0v-7H8v-5H3v12a1 1 0 0 0 1 1h8a1 1 0 0 0 1-1M9.5 5V2.12L12.38 5zM5.13 5h-.62v1.25h2.12V5zm-.62 3h7.12v1.25H4.5zm.62 3h-.62v1.25h7.12V11z" clip-rule="evenodd" fill="#666" fill-rule="evenodd"/></svg>
</file>

<file path="public/globe.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><g clip-path="url(#a)"><path fill-rule="evenodd" clip-rule="evenodd" d="M10.27 14.1a6.5 6.5 0 0 0 3.67-3.45q-1.24.21-2.7.34-.31 1.83-.97 3.1M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16m.48-1.52a7 7 0 0 1-.96 0H7.5a4 4 0 0 1-.84-1.32q-.38-.89-.63-2.08a40 40 0 0 0 3.92 0q-.25 1.2-.63 2.08a4 4 0 0 1-.84 1.31zm2.94-4.76q1.66-.15 2.95-.43a7 7 0 0 0 0-2.58q-1.3-.27-2.95-.43a18 18 0 0 1 0 3.44m-1.27-3.54a17 17 0 0 1 0 3.64 39 39 0 0 1-4.3 0 17 17 0 0 1 0-3.64 39 39 0 0 1 4.3 0m1.1-1.17q1.45.13 2.69.34a6.5 6.5 0 0 0-3.67-3.44q.65 1.26.98 3.1M8.48 1.5l.01.02q.41.37.84 1.31.38.89.63 2.08a40 40 0 0 0-3.92 0q.25-1.2.63-2.08a4 4 0 0 1 .85-1.32 7 7 0 0 1 .96 0m-2.75.4a6.5 6.5 0 0 0-3.67 3.44 29 29 0 0 1 2.7-.34q.31-1.83.97-3.1M4.58 6.28q-1.66.16-2.95.43a7 7 0 0 0 0 2.58q1.3.27 2.95.43a18 18 0 0 1 0-3.44m.17 4.71q-1.45-.12-2.69-.34a6.5 6.5 0 0 0 3.67 3.44q-.65-1.27-.98-3.1" fill="#666"/></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h16v16H0z"/></clipPath></defs></svg>
</file>

<file path="public/next.svg">
<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 394 80"><path fill="#000" d="M262 0h68.5v12.7h-27.2v66.6h-13.6V12.7H262V0ZM149 0v12.7H94v20.4h44.3v12.6H94v21h55v12.6H80.5V0h68.7zm34.3 0h-17.8l63.8 79.4h17.9l-32-39.7 32-39.6h-17.9l-23 28.6-23-28.6zm18.3 56.7-9-11-27.1 33.7h17.8l18.3-22.7z"/><path fill="#000" d="M81 79.3 17 0H0v79.3h13.6V17l50.2 62.3H81Zm252.6-.4c-1 0-1.8-.4-2.5-1s-1.1-1.6-1.1-2.6.3-1.8 1-2.5 1.6-1 2.6-1 1.8.3 2.5 1a3.4 3.4 0 0 1 .6 4.3 3.7 3.7 0 0 1-3 1.8zm23.2-33.5h6v23.3c0 2.1-.4 4-1.3 5.5a9.1 9.1 0 0 1-3.8 3.5c-1.6.8-3.5 1.3-5.7 1.3-2 0-3.7-.4-5.3-1s-2.8-1.8-3.7-3.2c-.9-1.3-1.4-3-1.4-5h6c.1.8.3 1.6.7 2.2s1 1.2 1.6 1.5c.7.4 1.5.5 2.4.5 1 0 1.8-.2 2.4-.6a4 4 0 0 0 1.6-1.8c.3-.8.5-1.8.5-3V45.5zm30.9 9.1a4.4 4.4 0 0 0-2-3.3 7.5 7.5 0 0 0-4.3-1.1c-1.3 0-2.4.2-3.3.5-.9.4-1.6 1-2 1.6a3.5 3.5 0 0 0-.3 4c.3.5.7.9 1.3 1.2l1.8 1 2 .5 3.2.8c1.3.3 2.5.7 3.7 1.2a13 13 0 0 1 3.2 1.8 8.1 8.1 0 0 1 3 6.5c0 2-.5 3.7-1.5 5.1a10 10 0 0 1-4.4 3.5c-1.8.8-4.1 1.2-6.8 1.2-2.6 0-4.9-.4-6.8-1.2-2-.8-3.4-2-4.5-3.5a10 10 0 0 1-1.7-5.6h6a5 5 0 0 0 3.5 4.6c1 .4 2.2.6 3.4.6 1.3 0 2.5-.2 3.5-.6 1-.4 1.8-1 2.4-1.7a4 4 0 0 0 .8-2.4c0-.9-.2-1.6-.7-2.2a11 11 0 0 0-2.1-1.4l-3.2-1-3.8-1c-2.8-.7-5-1.7-6.6-3.2a7.2 7.2 0 0 1-2.4-5.7 8 8 0 0 1 1.7-5 10 10 0 0 1 4.3-3.5c2-.8 4-1.2 6.4-1.2 2.3 0 4.4.4 6.2 1.2 1.8.8 3.2 2 4.3 3.4 1 1.4 1.5 3 1.5 5h-5.8z"/></svg>
</file>

<file path="public/vercel.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1155 1000"><path d="m577.3 0 577.4 1000H0z" fill="#fff"/></svg>
</file>

<file path="public/window.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 2.5h13v10a1 1 0 0 1-1 1h-11a1 1 0 0 1-1-1zM0 1h16v11.5a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 0 12.5zm3.75 4.5a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5M7 4.75a.75.75 0 1 1-1.5 0 .75.75 0 0 1 1.5 0m1.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5" fill="#666"/></svg>
</file>

<file path="src/app/dashboard/page.tsx">
import { BarChart, Card } from '@/components/ui'
import { getAnalytics } from '@/lib/actions'

export default async function DashboardPage() {
  const data = await getAnalytics()
  
  return (
    <div className="p-6 space-y-6">
      <h1 className="text-2xl font-bold">Analytics Dashboard</h1>
      
      <Card>
        <h2 className="text-lg mb-4">Trigger Activity</h2>
        <BarChart
          data={data.triggerUsage}
          xAxis="date"
          yAxis="count"
        />
      </Card>

      {/* Add more chart components */}
    </div>
  )
}
</file>

<file path="src/app/globals.css">
@import "tailwindcss";

:root {
  --background: #ffffff;
  --foreground: #171717;
}

@theme inline {
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  background: var(--background);
  color: var(--foreground);
  font-family: Arial, Helvetica, sans-serif;
}
</file>

<file path="src/app/layout.tsx">
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import { SupabaseProvider } from "@/lib/supabase-provider";
import "./globals.css";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body
        className={`${geistSans.variable} ${geistMono.variable} antialiased`}
      >
        <SupabaseProvider>
          {children}
        </SupabaseProvider>
      </body>
    </html>
  );
}
</file>

<file path="src/app/page.tsx">
import Image from "next/image";

export default function Home() {
  return (
    <div className="grid grid-rows-[20px_1fr_20px] items-center justify-items-center min-h-screen p-8 pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
      <main className="flex flex-col gap-[32px] row-start-2 items-center sm:items-start">
        <Image
          className="dark:invert"
          src="/next.svg"
          alt="Next.js logo"
          width={180}
          height={38}
          priority
        />
        <ol className="list-inside list-decimal text-sm/6 text-center sm:text-left font-[family-name:var(--font-geist-mono)]">
          <li className="mb-2 tracking-[-.01em]">
            Get started by editing{" "}
            <code className="bg-black/[.05] dark:bg-white/[.06] px-1 py-0.5 rounded font-[family-name:var(--font-geist-mono)] font-semibold">
              src/app/page.tsx
            </code>
            .
          </li>
          <li className="tracking-[-.01em]">
            Save and see your changes instantly.
          </li>
        </ol>

        <div className="flex gap-4 items-center flex-col sm:flex-row">
          <a
            className="rounded-full border border-solid border-transparent transition-colors flex items-center justify-center bg-foreground text-background gap-2 hover:bg-[#383838] dark:hover:bg-[#ccc] font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 sm:w-auto"
            href="https://vercel.com/new?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            <Image
              className="dark:invert"
              src="/vercel.svg"
              alt="Vercel logomark"
              width={20}
              height={20}
            />
            Deploy now
          </a>
          <a
            className="rounded-full border border-solid border-black/[.08] dark:border-white/[.145] transition-colors flex items-center justify-center hover:bg-[#f2f2f2] dark:hover:bg-[#1a1a1a] hover:border-transparent font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 w-full sm:w-auto md:w-[158px]"
            href="https://nextjs.org/docs?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            Read our docs
          </a>
        </div>
      </main>
      <footer className="row-start-3 flex gap-[24px] flex-wrap items-center justify-center">
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org/learn?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/file.svg"
            alt="File icon"
            width={16}
            height={16}
          />
          Learn
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://vercel.com/templates?framework=next.js&utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/window.svg"
            alt="Window icon"
            width={16}
            height={16}
          />
          Examples
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/globe.svg"
            alt="Globe icon"
            width={16}
            height={16}
          />
          Go to nextjs.org →
        </a>
      </footer>
    </div>
  );
}
</file>

<file path="src/components/ui/bar-chart.tsx">
'use client'

import { Bar } from 'react-chartjs-2'
import { 
  Chart as ChartJS, 
  CategoryScale, 
  LinearScale, 
  BarElement, 
  Title, 
  Tooltip, 
  Legend 
} from 'chart.js'

ChartJS.register(
  CategoryScale,
  LinearScale,
  BarElement,
  Title,
  Tooltip,
  Legend
)

interface BarChartProps {
  data: Array<{[key: string]: any}>
  xAxis: string
  yAxis: string
  title?: string
}

export function BarChart({ data, xAxis, yAxis, title }: BarChartProps) {
  const chartData = {
    labels: data.map(item => item[xAxis]),
    datasets: [{
      label: yAxis,
      data: data.map(item => item[yAxis]),
      backgroundColor: 'rgba(59, 130, 246, 0.5)'
    }]
  }

  const options = {
    responsive: true,
    plugins: {
      legend: {
        position: 'top' as const,
      },
      title: {
        display: !!title,
        text: title,
      },
    },
  }

  return <Bar options={options} data={chartData} />
}
</file>

<file path="src/components/ui/card.tsx">
import { cn } from '@/lib/utils'
import { ReactNode } from 'react'

interface CardProps {
  children: ReactNode
  className?: string
}

export function Card({ children, className }: CardProps) {
  return (
    <div className={cn(
      'rounded-lg border bg-card text-card-foreground shadow-sm',
      className
    )}>
      {children}
    </div>
  )
}
</file>

<file path="src/lib/actions.ts">
import { createClient } from './supabase'

export async function getAnalytics() {
  const supabase = createClient()
  const { data, error } = await supabase
    .from('activity_log')
    .select('*')
    .gte('created_at', new Date(Date.now() - 7 * 86400000).toISOString())
  
  if (error) throw error
  
  // Process data into chart formats
  return {
    triggerUsage: data.map(entry => ({
      date: new Date(entry.created_at).toLocaleDateString(),
      count: entry.action === 'trigger' ? 1 : 0
    }))
  }
}
</file>

<file path="src/lib/supabase-provider.tsx">
'use client'

import { createClient } from './supabase'
import { createContext, useContext, useState } from 'react'

const SupabaseContext = createContext(createClient())

export function SupabaseProvider({ children }: { children: React.ReactNode }) {
  const [supabase] = useState(() => createClient())
  
  return (
    <SupabaseContext.Provider value={supabase}>
      {children}
    </SupabaseContext.Provider>
  )
}

export const useSupabase = () => useContext(SupabaseContext)
</file>

<file path="src/lib/supabase.ts">
import { createBrowserClient } from '@supabase/ssr'
import { Database } from '@/types/supabase'

export function createClient() {
  return createBrowserClient<Database>(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_KEY!
  )
}
</file>

<file path="src/lib/utils.ts">
import { type ClassValue, clsx } from 'clsx'
import { twMerge } from 'tailwind-merge'

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}
</file>

<file path="src/types/supabase.ts">
import { PrismaClient } from '@prisma/client'

export type Database = typeof PrismaClient
export type User = PrismaClient['user']
export type Trigger = PrismaClient['trigger']
export type Template = PrismaClient['template']
export type ActivityLog = PrismaClient['activityLog']
</file>

<file path=".gitignore">
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

/src/generated/prisma
</file>

<file path="eslint.config.mjs">
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  ...compat.extends("next/core-web-vitals", "next/typescript"),
];

export default eslintConfig;
</file>

<file path="next.config.ts">
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  /* config options here */
};

export default nextConfig;
</file>

<file path="package.json">
{
  "name": "admin",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev --turbopack",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@prisma/client": "^6.9.0",
    "@supabase/auth-helpers-nextjs": "^0.10.0",
    "@supabase/ssr": "^0.6.1",
    "@supabase/supabase-js": "^2.50.0",
    "next": "15.3.3",
    "prisma": "^6.9.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@tailwindcss/postcss": "^4",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "15.3.3",
    "tailwindcss": "^4",
    "typescript": "^5"
  }
}
</file>

<file path="postcss.config.mjs">
const config = {
  plugins: ["@tailwindcss/postcss"],
};

export default config;
</file>

<file path="README.md">
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}
</file>

</files>
</file>

<file path="documentation/api_spec.md">
# API Specification

## Admin Panel API (Next.js Routes)

### Authentication
- All routes require valid JWT from Supabase Auth
- Token passed in `Authorization` header

### Trigger Management
`POST /api/triggers`
```json
{
  "post_id": "INSTAGRAM_POST_ID",
  "keyword": "WIN",
  "template_id": "UUID",
  "is_active": true
}
```
Response:
```json
{
  "id": "UUID",
  "created_at": "ISO8601"
}
```

`GET /api/triggers?post_id=INSTAGRAM_POST_ID`
```json
[
  {
    "id": "UUID",
    "keyword": "WIN",
    "template": { /* template object */ },
    "is_active": true
  }
]
```

### Template Management
`POST /api/templates`
```json
{
  "content": "Congrats! You won!",
  "media_url": "https://storage.example.com/prize.jpg"
}
```

## Bot Service API (Python)

### Health Check
`GET /bot/health`
```json
{
  "status": "ok",
  "last_check": "ISO8601",
  "queued_messages": 5
}
```

### Configuration
`GET /bot/config`
```json
{
  "active_triggers": [
    {
      "post_id": "INSTAGRAM_POST_ID",
      "keyword": "WIN",
      "template": { /* template object */ }
    }
  ]
}
```

## Supabase Integration

### Authentication
`POST /auth/v1/token?grant_type=password`
```json
{
  "email": "admin@example.com",
  "password": "secret"
}
```

### Storage
`POST /storage/v1/object/templates/{filename}`
- Requires Bearer token
- Max file size: 10MB
- Allowed types: image/jpeg, image/png, video/mp4

## Error Responses
Common error formats:
```json
{
  "error": "ERROR_CODE",
  "message": "Human-readable description"
}
```

### Status Codes
- 401 Unauthorized - Invalid/missing token
- 403 Forbidden - Insufficient permissions
- 429 Too Many Requests - Rate limit exceeded
</file>

<file path="documentation/business_requirements.md">
# Business Requirements Document

## Project Overview
Automated Instagram engagement system that:
- Sends DMs to users who comment with specific keywords
- Provides admins with web-based control panel for configuration
- Runs locally via Docker for easy testing

## Key Objectives
1. Increase user engagement through automated responses
2. Simplify campaign management for admins
3. Ensure system reliability and scalability
4. Maintain secure access to admin features

## Stakeholders
- **Instagram Users**: Receive automated DMs based on comments
- **Marketing Admins**: Manage trigger keywords and DM content
- **Developers**: Maintain and extend system functionality

## User Stories

### Instagram User Perspective
- As a user, I want to receive relevant DMs when I comment with specific keywords
- As a user, I want the DM content to match the keyword I used
- As a user, I want to receive media attachments in DMs when available

### Admin Perspective
- As an admin, I want to:
  - Create/edit/delete trigger keywords
  - Manage DM templates (text + media)
  - Monitor bot activity
  - Toggle triggers on/off
- As an admin, I need secure login to the control panel
- As an admin, I want to see statistics on trigger usage

## Success Metrics
1. 80% of keyword comments receive DMs within 5 minutes
2. Admin can configure new triggers in under 2 minutes
3. System uptime of 99.9% during campaign periods
4. Zero unauthorized access to admin panel

## Key Features
### Instagram Bot
- Real-time comment monitoring
- Keyword matching logic
- DM template selection
- Media attachment handling

### Admin Panel
- User authentication
- CRUD operations for:
  - Trigger keywords
  - DM templates
- Activity dashboard
- System health monitoring

## Constraints
- Must run in Docker environment
- Instagram API rate limits
- 2FA requirements for admin access
- Local development focus initially
</file>

<file path="documentation/database_schema.md">
# Database Schema

## Tables Overview
```mermaid
erDiagram
    users ||--o{ triggers : "manages"
    triggers }o--|| templates : "uses"
    users ||--o{ activity_log : "performs"
    
    users {
        uuid id
        string email
        timestamp created_at
    }
    
    triggers {
        uuid id
        uuid user_id
        uuid template_id
        string post_id
        string keyword
        boolean is_active
        timestamp created_at
    }
    
    templates {
        uuid id
        string content
        string media_url
        json metadata
        timestamp created_at
    }
    
    activity_log {
        uuid id
        uuid user_id
        string action
        json details
        timestamp created_at
    }
```

## Table Details

### `users` (Supabase Auth)
- Extends default Supabase auth.users table
- Stores admin panel users
- **Relationships**:
  - Has many `triggers`
  - Has many `activity_log` entries

### `triggers`
- Stores Instagram post/keyword configurations
- **Fields**:
  - `post_id`: Instagram post ID to monitor
  - `keyword`: Trigger word/phrase
  - `is_active`: Enable/disable toggle
- **Indexes**:
  - `idx_triggers_post_id` (post_id)
  - `idx_triggers_keyword` (keyword)

### `templates`
- Stores DM response content
- **Fields**:
  - `content`: Message text (supports variables)
  - `media_url`: Optional image/video URL
  - `metadata`: Additional config (e.g., buttons)
  
### `activity_log`
- Tracks system events
- **Fields**:
  - `action`: Event type (e.g., "dm_sent")
  - `details`: JSON payload with context

## Sample Queries

1. Get active triggers for a post:
```sql
SELECT * FROM triggers 
WHERE post_id = 'INSTAGRAM_POST_ID' 
AND is_active = true;
```

2. Get template for a keyword:
```sql
SELECT t.* FROM templates t
JOIN triggers tr ON tr.template_id = t.id
WHERE tr.keyword = 'WIN'
LIMIT 1;
```

3. Recent admin activity:
```sql
SELECT * FROM activity_log
WHERE user_id = 'ADMIN_UUID'
ORDER BY created_at DESC
LIMIT 10;
</file>

<file path="documentation/deployment_guide.md">
# Deployment Guide

## Prerequisites
- Docker 20.10+
- Docker Compose 2.20+
- 4GB RAM minimum

## Quick Start
```bash
# Clone repository
git clone https://github.com/your-repo/instagram-bot.git
cd instagram-bot

# Start services
docker-compose up -d
```

## Docker Compose Configuration
```yaml
version: '3.8'

services:
  admin-panel:
    image: node:18
    working_dir: /app
    volumes:
      - ./admin:/app
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgres://postgres:password@db:5432/postgres
    depends_on:
      - db

  bot-service:
    image: python:3.10
    working_dir: /app
    volumes:
      - ./bot:/app
    environment:
      - INSTAGRAM_USER=your_username
      - INSTAGRAM_PASSWORD=your_password
    depends_on:
      - db

  db:
    image: supabase/postgres:15
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_PASSWORD=password
    volumes:
      - pgdata:/var/lib/postgresql/data

volumes:
  pgdata:
```

## Environment Variables

### Admin Panel (Next.js)
```env
NEXT_PUBLIC_SUPABASE_URL=http://db:5432
NEXT_PUBLIC_SUPABASE_KEY=your-anon-key
```

### Bot Service
```env
INSTAGRAM_USER=your_instagram_username
INSTAGRAM_PASSWORD=your_instagram_password
POLL_INTERVAL=60 # seconds
```

## Initial Setup
1. Create admin user:
```bash
docker-compose exec admin-panel npm run create-admin
```

2. Import initial triggers (optional):
```bash
docker-compose exec admin-panel npm run import-triggers triggers.csv
```

## Testing
1. Verify services are running:
```bash
docker-compose ps
```

2. Check admin panel:
```bash
curl http://localhost:3000/api/health
```

3. Test bot service:
```bash
docker-compose exec bot-service python test_bot.py
```

## Troubleshooting
Common issues:
- Instagram API limits: Check bot logs
```bash
docker-compose logs bot-service
```
- Database connection issues: Verify credentials
- Admin panel not loading: Check Next.js build
```bash
docker-compose exec admin-panel npm run build
</file>

<file path="documentation/functional_requirements.md">
# Functional Requirements

## Instagram Bot Functionality

### Comment Monitoring
- Continuously polls Instagram API for new comments
- Filters comments based on:
  - Post ID (configured triggers only)
  - Keyword matches (exact and partial matches)
  - User eligibility (exclude blocked users)

### Keyword Matching
- Supports:
  - Exact match triggers (e.g., "WIN")
  - Partial match triggers (e.g., "promo*")
  - Case-insensitive matching
- Priority system for multiple matches

### DM Response System
- Selects appropriate template based on:
  - Matched keyword
  - User history (avoid duplicates)
- Sends DM containing:
  - Preconfigured text
  - Optional media attachment
  - Tracking pixel for analytics
- Rate limiting: Max 1 DM per user per hour

## Admin Panel Features

### Authentication
- Supabase email/password login
- Session management (30min timeout)
- Role-based access (Admin/Viewer)

### Trigger Management
- CRUD operations for:
  - Post IDs to monitor
  - Trigger keywords
  - Response templates
- Activation toggle per trigger
- Bulk import/export via CSV

### Template Management
- Create/edit DM templates with:
  - Text content (markdown supported)
  - Media attachments (images/videos)
  - Tracking parameters
- Preview functionality
- Version history

### Dashboard
- Real-time metrics:
  - Total triggers activated
  - DMs sent (success/failure)
  - Popular keywords
- System health monitoring

## System Constraints
- Instagram API rate limits:
  - Max 200 comments/min
  - Max 30 DMs/min
- Local storage limits:
  - 1GB media cache
  - 7d activity logs
- Performance targets:
  - <2s response time for admin panel
  - <5s DM delivery after comment

## Error Handling
- Failed DM retries (3 attempts)
- Invalid comment skipping
- API outage recovery:
  - 15min backoff period
  - Local queue for pending DMs
- Admin alerts for:
  - Continuous failures
  - Storage limits
  - Auth breaches
</file>

<file path="documentation/master_plan.md">
# Master Documentation Plan

Based on the vision in [`app_description.md`](app_description.md), create the following documents:

- [x] **1. Business Requirements Document** (`documentation/business_requirements.md`)
  - Project overview and objectives
  - Stakeholder analysis
  - User stories for:
    - Instagram users receiving DMs
    - Admin users managing triggers
  - Success metrics

- [x] **2. Functional Requirements** (`documentation/functional_requirements.md`)
  - Instagram bot functionality:
    - Comment monitoring workflow
    - Keyword matching logic
    - DM sending process
  - Admin panel features:
    - Authentication flow
    - CRUD operations for triggers
    - DM template management
  - System constraints and edge cases

- [x] **3. Technical Design Specification** (`documentation/technical_design.md`)
  - System architecture diagram
  - Component breakdown:
    - Instagram bot service
    - Admin panel (Next.js)
    - Database layer
  - API specifications:
    - Internal bot-admin communication
    - Supabase integration points
  - Security considerations

- [x] **4. Database Schema** (`documentation/database_schema.md`)
  - Supabase tables:
    - `users` (Supabase Auth)
    - `triggers` (keyword configurations)
    - `dm_templates` (response content)
    - `activity_log` (bot operations)
  - Relationships and indexes
  - Sample queries

- [x] **5. API Documentation** (`documentation/api_spec.md`)
  - Admin panel API routes:
    - /api/triggers (CRUD)
    - /api/templates (CRUD)
  - Bot healthcheck endpoints
  - Authentication requirements
  - Request/response examples

- [x] **6. Deployment Guide** (`documentation/deployment_guide.md`)
  - Docker compose configuration
  - Environment variables
  - Initial setup steps
  - Local development workflow
  - Testing procedures
</file>

<file path="documentation/technical_design.md">
# Technical Design Specification

## System Architecture
```text
[Instagram Users] <-> [Instagram API] <-> [Python Bot Service]
                             ^
                             |
                             v
[Admin Users] <-> [Next.js Admin Panel] <-> [Supabase Database]
```

### Components
1. **Instagram Bot Service** (Python)
   - Comment polling every 60s
   - Keyword matching engine
   - DM sending queue
   - Error handling and retries

2. **Admin Panel** (Next.js 14)
   - App Router structure:
     - `/app/login` - Auth page
     - `/app/dashboard` - Main interface
     - `/app/triggers` - CRUD operations
   - API Routes:
     - `/api/triggers` - Manage keywords
     - `/api/templates` - Handle DM content

3. **Database** (Supabase)
   - Tables:
     - `triggers` (post_id, keyword, template_id, is_active)
     - `templates` (content, media_url, metadata)
     - `activity_log` (timestamp, user_id, action)

## API Specifications

### Bot Service API
- POST `/bot/healthcheck` - Monitoring endpoint
- GET `/bot/config` - Retrieve active triggers

### Admin Panel API
- CRUD endpoints for all database tables
- JWT authentication via Supabase

### Supabase Integration
- Auth: Email/password with sessions
- Storage: Media files for DM templates
- Realtime: Updates to trigger configurations

## Security Design
- Rate limiting on public endpoints
- JWT validation for admin API
- Encrypted database connections
- Regular security audits

## Infrastructure
- Docker Compose setup:
  - `admin-panel` service (Next.js)
  - `bot-service` service (Python)
  - `supabase` service (local emulator)
- Environment variables for configuration
- Health monitoring endpoints

## Performance Considerations
- Caching of frequent API calls
- Bulk operations for trigger updates
- Async processing for DM delivery
</file>

<file path="supabase/.gitignore">
# Supabase
.branches
.temp

# dotenvx
.env.keys
.env.local
.env.*.local
</file>

<file path="todos/dev_todo_phase_4.md">
# Phase 4: Activity Log Implementation

## 1. Create Activity Log Page
- **Create `admin/admin/src/app/dashboard/activity/page.tsx`**:
  - Display page title "Activity Log"
  - Add data table component
  - Implement pagination controls

## 2. Build Activity Table Component
- **Create `admin/admin/src/components/activity-table.tsx`**:
  - Show columns: Action, Details, Timestamp
  - Implement sorting by timestamp
  - Add filtering by action type

## 3. Fetch Activity Data
- **Modify `admin/admin/src/lib/actions.ts`**:
  - Add `getActivityLogs()` function
  - Query database using Prisma
  - Return paginated results

## 4. Add Sidebar Navigation
- **Update `admin/admin/src/components/sidebar.tsx`**:
  - Add "Activity Log" menu item
  - Link to "/dashboard/activity"
  - Use appropriate icon

## Verification Steps
1. Navigate to Activity Log page
2. Verify data loads correctly
3. Test sorting and filtering
4. Check pagination functionality
</file>

<file path="app_description.md">
# Instagram Comment-to-DM Bot System

## Project Vision
Create an automated system where:
1. Users commenting with specific keywords on Instagram posts receive automated DMs
2. Admins can manage triggers and DM content through a web panel
3. Entire system runs locally via Docker for easy testing

## Core Components
### Instagram Bot
- Python-based service monitoring Instagram comments
- Matches comments against admin-defined keywords
- Sends pre-configured DM responses (text/media) to matching users
- Runs in background 24/7

### Admin Panel
- Next.js 14 application with App Router
- Authentication via Supabase Auth
- CRUD operations for:
  - Instagram post triggers (keywords)
  - DM response templates (text/media)
  - Activation status
- Dashboard showing trigger statistics
- Tailwind CSS for styling

### Database & Storage
- Supabase PostgreSQL for:
  - User accounts (Supabase Auth)
  - Trigger configurations
  - DM templates
- Supabase Storage for media files in DMs

## Tech Stack
### Backend Services
- Instagram Bot: Python + Instagram API wrapper
- Admin API: Next.js API routes

### Frontend
- Next.js 14
- Tailwind CSS
- Prisma ORM

### Infrastructure
- Docker Compose for local development
- Supabase for:
  - Authentication
  - Database
  - File storage

## Key Requirements
1. Single-command startup: `docker-compose up`
2. Isolated services:
   - Admin panel (Next.js)
   - Instagram bot (Python)
   - Database (Supabase local)
3. Secure admin authentication
4. Configurable triggers/DM content
</file>

<file path=".roo/rules-architect-senior/rules.md">
You are the **Architect AI**, designated as **🧠 Architect**. You are the master strategist and planner. You operate in two distinct modes: **PLANNING & VERIFICATION** (for generating the development roadmap) and **STRATEGIC INTERVENTION** (for fixing deep-seated failures that tactical fixes could not resolve). Your purpose is to provide a flawless, context-aware, and fully executable plan for the Developer AI, and to correct the plan when it's fundamentally flawed.

## 2. THE AUTONOMOUS OPERATIONAL LOOP

Upon activation, you must determine your operational mode by checking for signal files in the following order of priority:

1.  `NEEDS_FINAL_VERIFICATION.md` (triggers Final Verification Mode)
2.  `NEEDS_ARCHITECTURAL_REVIEW.md` (triggers Strategic Intervention Mode)
3.  Default (triggers Planning & Verification Mode)

---

### **2.1. FINAL VERIFICATION MODE (Project QA)**

**Trigger:** This is your highest priority mode, activated when `NEEDS_FINAL_VERIFICATION.md` is present. Your task is to perform the final quality assurance check on the entire project.

1.  **Acknowledge & Cleanup:**
    *   **Announce:** "Initiating final project verification against app description and documentation."
    *   **Action:** Delete the `NEEDS_FINAL_VERIFICATION.md` signal file.
2.  **Perform Holistic Analysis:**
    *   **Execute Command:** Run `repomix` to get a complete snapshot of the final codebase and all documentation.
    *   **Ingest All Truths:** Read and fully comprehend `repomix-output.xml`, `app_description.md`, and all files in the `/documentation` directory.
    *   **LLM Prompt:** "Perform a final, holistic project audit. Compare the codebase and the documentation against the original `app_description.md`. Answer the following questions:
        1. Does the implemented code fulfill every requirement and feature outlined in `app_description.md`?
        2. Is the documentation in the `/documentation` directory an accurate, up-to-date representation of the final codebase?
        3. Are there any discrepancies between the app description, the documentation, and the code?
        Provide a clear verdict: `PASSED` or `FAILED`. If `FAILED`, provide a detailed list of all discrepancies."
3.  **Verdict and Action:**
    *   **If Verdict is `PASSED`:**
        *   **Announce:** "Final verification PASSED. The project is complete and correct."
        *   **Action:** Create the final signal file `PROJECT_VERIFIED_AND_COMPLETE.md`.
        *   **Handoff:** Switch mode to `<mode>orchestrator-senior</mode>` for final termination.
    *   **If Verdict is `FAILED`:**
        *   **Announce:** "Final verification FAILED. Generating a fix plan to address discrepancies."
        *   **Action:** Create a new `FIX_PLAN.md` that contains precise, atomic tasks for the Developer AI to correct the discrepancies in either the code or the documentation.
        *   **Handoff:** Switch mode to `<mode>orchestrator-senior</mode>`.

---

### **2.2. STRATEGIC INTERVENTION MODE (Fixing a Fundamentally Broken Plan)**

**Trigger:** This mode is activated by the Orchestrator when a `NEEDS_ARCHITECTURAL_REVIEW.md` file is present. This signal means a lower-level fix has already failed, and the problem is complex or systemic.

1.  **Read Escalation Report:** Open and parse the `NEEDS_ARCHITECTURAL_REVIEW.md` file. It contains the original problem, the failed fix plan, and error logs.
2.  **Perform Deep Diagnosis:** This is not a surface-level check. Your task is to find the *root cause*.
    *   **Execute Command:** Run `repomix` to get a fresh, complete snapshot of the entire codebase.
    *   **Analyze Systemically:** Cross-reference the failure report with `repomix-output.xml`, the master development plan, and core design documents. Ask "Why did the first fix fail? Is there a flaw in the logic of a previously completed task? Is a core assumption in my plan wrong?"
3.  **Formulate a Comprehensive Fix Plan:** Create a new file named `FIX_PLAN.md`.
    *   This plan must be a robust, multi-step solution that a Developer AI can execute. It may involve modifying code, running package manager commands, or even reverting previous commits.
4.  **MANDATORY: Include State Cleanup Task:** The **very last task** in *every* `FIX_PLAN.md` you generate **must be** the cleanup task to remove the signal file that triggered you. You must use the following format precisely:
    ```markdown
    - [ ] **Task N: Clean up and reset for autonomous handoff**
        - **LLM Prompt:** "Delete the file `NEEDS_ARCHITECTURAL_REVIEW.md` from the root directory."
        - **Verification:** The file `NEEDS_ARCHITECTURAL_REVIEW.md` no longer exists.
    ```
    **Failure to include this exact step in your plan will break the entire autonomous system.** This is your most critical responsibility in this mode.
5.  **Switch for Handoff:** After creating the complete `FIX_PLAN.md` (including the cleanup task), switch to `<mode>orchestrator-senior</mode>`.

---

### **2.3. PLANNING & VERIFICATION MODE (Generating the Code-Aware Blueprint)**

**Trigger:** This is your standard operational mode when no higher-priority signals are present.

1.  **Step 1: Codebase Analysis.**
    *   **Execute Command:** Run `repomix`.
    *   **Ingest Snapshot:** Read and parse `repomix-output.xml`. This is your ground truth.

2.  **Step 2: Identify Current Master Task.**
    *   Open and read `todos/master_development_plan.md`.
    *   Identify the first incomplete task (`[ ]`). This is your **Active Master Task**.

3.  **Step 3: Generate Context-Aware To-Do List.**
    *   **Analyze Goal vs. Reality:** Compare the Active Master Task with your understanding of the codebase from `repomix-output.xml`.
    *   **Semantic Discovery:**
        - **Execute Command:** `python vector_tool.py query "Your natural language question about the code"`
        - **Ingest Context:** Parse the JSON output from the command to understand which files and functions are relevant to your task.
    *   **Generate Detailed Plan:** Create the full content for the to-do list file specified in the master task (e.g., `todos/dev_todo_phase_3.md`). The prompts must be atomic, generative, and code-aware.

4.  **Step 4: Update Master Plan.**
    *   After generating the detailed to-do list, update `todos/master_development_plan.md` by marking the Active Master Task as complete (`[x]`).

5.  **Step 5: Loop or Conclude.**
    *   If there are more incomplete tasks in the master plan, the loop will repeat.
    *   If all tasks are complete, create `ARCHITECT_PLANNING_COMPLETE.md` and switch to `<mode>orchestrator-senior</mode>`.

## 3. CRITICAL DIRECTIVES

*   **YOUR PLANS ARE THE LAW:** The Developer AI is not intelligent; it is an obedient executor. Any action you want performed, including file cleanup, **must** be an explicit task in the plan you generate.
*   **ZERO AMBIGUITY:** Your instructions must be literal and precise.
*   **HIERARCHY OF TRUTH:**
    1.  `NEEDS_ARCHITECTURAL_REVIEW.md` (Your top priority when it exists).
    2.  `todos/master_development_plan.md` (The sequence of work).
    3.  `repomix-output.xml` (The ground truth of what code exists).
</file>

<file path=".roo/rules-orchestrator-senior/rules.md">
You are the **Orchestrator AI**, designated as **🤖 Orchestrator**. You are the master process manager, central router, and state janitor for the autonomous development system. You are executed for a **single, one-shot decision-making task**: to analyze the repository's current state, clean up any completed work artifacts, and hand off control to the appropriate specialist.

## 2. THE CORE MISSION (One-Shot Execution)

Your mission is to perform a single, definitive analysis of the repository. You will run a state cleanup protocol first, then immediately switch to the correct operational mode based on the resulting clean state.

## 3. THE ORCHESTRATION DECISION TREE

Upon activation, you will check for the existence of the following files in this **strict, descending order of priority**. You must execute the action for the **first matching condition**.

1.  **If `PROJECT_VERIFIED_AND_COMPLETE.md` exists:** (HIGHEST PRIORITY)
    *   **Analysis:** The project has been fully developed and verified by the Senior Architect.
    *   **Announcement:** "SUCCESS: Project is verified and complete. Halting all operations."
    *   **Action:** Terminate all processes.

2.  **If `DEVELOPMENT_COMPLETE.md` exists:**
    *   **Analysis:** The Developer has signaled that all planned work is finished. The project requires final verification.
    *   **Announcement:** "Development phase complete. Preparing for final project verification."
    *   **Action:**
        1.  Delete the `DEVELOPMENT_COMPLETE.md` file.
        2.  Create a new signal file named `NEEDS_FINAL_VERIFICATION.md`.
        3.  **Restart your own decision process from the top of this list.**

3.  **If `NEEDS_FINAL_VERIFICATION.md` exists:**
    *   **Analysis:** The project is ready for a final, holistic review.
    *   **Announcement:** "Handing off to Senior Architect for final codebase and documentation verification."
    *   **Action:** Switch mode: `<mode>architect-senior</mode>`.

4.  **If `NEEDS_ARCHITECTURAL_REVIEW.md` exists:**
    *   **Analysis:** A tactical fix has failed. The core plan requires re-evaluation by the master strategist.
    *   **Announcement:** "Escalation signal detected. A tactical fix has failed. Switching to Senior Architect for deep analysis and strategic intervention."
    *   **Action:** Switch mode: `<mode>architect-senior</mode>`.

5.  **If `NEEDS_ASSISTANCE.md` exists:**
    *   **Analysis:** A standard development or verification task has failed. A first-level response is required.
    *   **Announcement:** "Distress signal detected. Switching to Emergency mode for tactical diagnosis."
    *   **Action:** Switch mode: `<mode>emergency</mode>`.

6.  **If `FIX_PLAN.md` exists:**
    *   **Analysis:** A fix plan exists. I must determine if it is complete or pending execution.
    *   **Action (Conditional Logic):**
        *   **Read the `FIX_PLAN.md` file.**
        *   **If the file contains the string `[ ]`:**
            *   **Verdict:** The plan has pending tasks.
            *   **Announcement:** "Pending fix plan detected. Switching to Developer mode for execution."
            *   **Action:** Switch mode: `<mode>developer</mode>`.
        *   **If the file does NOT contain the string `[ ]`:**
            *   **Verdict:** The plan was successfully completed by the developer, but the artifact remains. My role is to clean it up.
            *   **Announcement:** "Completed fix plan detected. Cleaning up state file and re-evaluating."
            *   **Action:** Delete the `FIX_PLAN.md` file, and then **restart your own decision process from the top of this list.**

7.  **If `ARCHITECT_PLANNING_COMPLETE.md` exists:**
    *   **Analysis:** The Architect has finished planning, and development can begin. This is a one-time signal that must be consumed.
    *   **Announcement:** "Architectural planning is complete. Consuming signal and handing off to Developer."
    *   **Action:**
        1.  Delete the `ARCHITECT_PLANNING_COMPLETE.md` file.
        2.  Switch mode: `<mode>developer</mode>`.

8.  **Default - If none of the above conditions are met:**
    *   **Analysis:** The repository is in a clean state, with no emergencies or pending fixes. The system should proceed with the next phase of planning.
    *   **Announcement:** "No critical signals found. Switching to Architect mode for standard planning."
    *   **Action:** Switch mode: `<mode>architect-senior</mode>`.

## 4. CRITICAL DIRECTIVES
*   **CLEAN THEN DECIDE:** Your primary responsibility is to ensure a clean state before delegating. A completed `FIX_PLAN.md` or `ARCHITECT_PLANNING_COMPLETE.md` is a temporary artifact that you **must** clean up.
*   **ONE SHOT, NO LOOPS:** You execute one branch of the decision tree and then immediately hand off control. If you clean up a file, you must re-run the tree to ensure the correct handoff from the new state.
*   **PRIORITY IS LAW:** You must check for signals in the exact order specified.
</file>

<file path=".roo/rules-planner-architect/rules.md">
You are the **Planner_Architect AI**, the master designer and strategist. You operate in two distinct modes: **Blueprint Mode** (generating high-level SDLC documentation) and **Development Planning Mode** (creating code-aware, atomic tasks for the developer). Your purpose is to translate abstract requirements into a flawless, executable plan.

## 2. THE DUAL-MODE OPERATIONAL LOOP

Upon activation, you must first determine your operational mode by checking the state of the repository.

### 2.1. MODE 1: BLUEPRINT CREATION & VERIFICATION

**Trigger:** This mode is active if `documentation/master_plan.md` exists and contains incomplete tasks `[ ]`. It operates in two sequential phases.

#### Phase 1: Document Generation
1.  **Initialize Manifest (First Run Only):** If `documentation/file_manifest.md` does not exist, create it with the heading `# Project File Manifest`.
2.  **Identify Task:** Open `documentation/master_plan.md` and find the first incomplete task.
3.  **Consult Vision:** Read `app_description.md` to understand the core requirements.
4.  **Generate Document:** Create the full, detailed content for the documentation file specified in the task (e.g., `documentation/business_requirements.md`). You must generate complete content, leaving no placeholders.
5.  **Update Manifest:** Append the full path of the newly created document to `documentation/file_manifest.md`.
6.  **Update Master Plan:** Mark the task as complete `[x]` in `documentation/master_plan.md`.
7.  **Loop:** If more incomplete tasks exist in `documentation/master_plan.md`, repeat from step 2.

#### Phase 2: Blueprint Self-Verification

**Trigger:** This phase begins automatically after all tasks in `documentation/master_plan.md` are marked complete.

1.  **Analyze Blueprint:**
    *   **Execute Command:** Run `repomix` to generate `repomix-output.xml`.
    *   **Ingest:** Read `repomix-output.xml`, `app_description.md`, and `documentation/file_manifest.md`.
2.  **Verify against Vision:**
    *   **LLM Prompt:** "Perform a comprehensive review. Compare the documentation listed in `file_manifest.md` against the requirements in `app_description.md`. Does the documentation suite fully and accurately cover every feature, user story, and constraint mentioned in the app description? List any specific discrepancies, missing sections, or ambiguities."
3.  **Decision & Action:**
    *   **If Discrepancies Found:**
        *   **LLM Prompt:** "Based on the discrepancies found, generate a series of precise modification prompts to correct the documentation files. Address each issue one by one until the documentation is in full alignment with `app_description.md`."
        *   Execute the modifications.
        *   Repeat this verification phase from step 1.
    *   **If Verification Passes:**
        *   **Announce:** "Blueprint verification passed. Documentation is complete and aligned with the project vision."
        *   **Action:** Create the signal file `BLUEPRINT_COMPLETE.md`.
        *   **Handoff:** Switch mode to `<mode>planner-orchestrator</mode>`.

### 2.2. MODE 2: CODE-AWARE DEVELOPMENT PLANNING

**Trigger:** This mode is active if `todos/master_development_plan.md` exists and contains incomplete tasks `[ ]`.

1.  **Identify Phase:** Open `todos/master_development_plan.md` and find the first incomplete phase (`[ ]`). Let's say it's "Phase 2: User Authentication".
2.  **Analyze Current Reality (Codebase Mapping):**
    *   **Execute Command:** Run `repomix` to generate the `repomix-output.xml` file. This is your ground truth of what currently exists.
    *   **Ingest Snapshot:** Read and fully comprehend the `repomix-output.xml` file.
3.  **Generate Atomic Plan:**
    *   **Cross-Reference:** Compare the goal of the current phase ("User Authentication") with the existing codebase reality from `repomix-output.xml` and the project documentation.
    *   **Create Detailed To-Do:** Create a new file, `todos/dev_todo_phase_2.md`. This file must contain a series of atomic, unambiguous, generative prompts for the Developer AI.
    *   **BE CODE-AWARE:** Your prompts must reflect the current state.
        *   *Bad Prompt:* "Create a login page."
        *   *Good Prompt:* "**Modify `src/app/login/page.tsx`**: Import the `useFormState` hook from React. Add state management for email and password fields. Modify the form's `onSubmit` handler to call a new server action named `loginUser`."
4.  **Update Master Development Plan:** After successfully generating the detailed `dev_todo_phase_2.md` file, update `todos/master_development_plan.md` by marking the current phase as complete (`[x]`).
5.  **Handoff for Execution:** Announce "Detailed plan for Phase 2 created. Switching to orchestrator to begin implementation." and switch mode to `<mode>planner-orchestrator</mode>`.

## 3. HIERARCHY OF TRUTH

1.  **`app_description.md`**: The ultimate vision.
2.  **`repomix-output.xml`**: The undeniable truth of what code has been written.
3.  **Existing Documentation**: The formal requirements you have already written.

## 4. CRITICAL DIRECTIVES
*   **ZERO AMBIGUITY:** Your plans for the Developer AI must be so clear that a simple 4B model can execute them without questions.
*   **GENERATIVE PROMPTS:** Phrase all tasks as direct instructions for an LLM (e.g., "Generate a file...", "Modify the file to include...").
*   **STATEFUL PROGRESSION:** Your primary job is to work through master plan files, updating them as you complete each major item.
</file>

<file path="admin/admin/src/app/layout.tsx">
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import { SupabaseProvider } from "@/lib/supabase-provider";
import "./globals.css";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body
        className={`${geistSans.variable} ${geistMono.variable} antialiased`}
      >
        <SupabaseProvider>
          {children}
        </SupabaseProvider>
      </body>
    </html>
  );
}
</file>

<file path="admin/admin/src/components/ui/bar-chart.tsx">
'use client'

import { Bar } from 'react-chartjs-2'
import { 
  Chart as ChartJS, 
  CategoryScale, 
  LinearScale, 
  BarElement, 
  Title, 
  Tooltip, 
  Legend 
} from 'chart.js'

ChartJS.register(
  CategoryScale,
  LinearScale,
  BarElement,
  Title,
  Tooltip,
  Legend
)

type BarChartDataItem = Record<string, unknown> // Generic chart data type

interface BarChartProps {
  datasets: BarChartDataItem[]
  xAxis: string
  yFields: string[]
  title?: string
  colors?: string[]
}

export function BarChart({ datasets, xAxis, yFields, title, colors }: BarChartProps) {
  const chartData = {
    labels: datasets.map(item => item[xAxis]),
    datasets: yFields.map((field, index) => ({
      label: field,
      data: datasets.map(item => item[field]),
      backgroundColor: colors?.[index] || 'rgba(59, 130, 246, 0.5)'
    }))
  }

  const options = {
    responsive: true,
    plugins: {
      legend: {
        position: 'top' as const,
      },
      title: {
        display: !!title,
        text: title,
      },
      tooltip: {
        mode: 'index' as const,
        intersect: false,
      },
    },
    interaction: {
      mode: 'index' as const,
      intersect: false,
    },
  }

  return <Bar options={options} data={chartData} />
}
</file>

<file path="admin/admin/src/lib/supabase.ts">
import { createBrowserClient } from '@supabase/ssr'
import { Database } from '@/types/database'

export function createClient() {
  return createBrowserClient<Database>(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_KEY!
  )
}
</file>

<file path="admin/admin/.gitignore">
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

/src/generated/prisma
</file>

<file path="admin/admin/tsconfig.json">
{
  "compilerOptions": {
    "target": "es5",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "forceConsistentCasingInFileNames": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"],
      "@/bot-monitor/*": ["../../bot-monitor/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}
</file>

<file path="bot-monitor/types.ts">
export interface BotHealthStatus {
  lastPing: Date;
  isHealthy: boolean;
  errorCount: number;
}

export interface ActivityEvent {
  type: 'message' | 'error' | 'response' | 'warning';
  timestamp: Date;
  details: string;
  metadata?: {
    responseTime?: number;
    recipient?: string;
    messageId?: string;
    errorStack?: string;
    content?: string;
  };
}

export interface RateLimitConfig {
  maxEvents: number;
  timeWindow: number; // in milliseconds
}
</file>

<file path="supabase/config.toml">
# For detailed configuration reference documentation, visit:
# https://supabase.com/docs/guides/local-development/cli/config
# A string used to distinguish different Supabase projects on the same host. Defaults to the
# working directory name when running `supabase init`.
project_id = "arina_admin_instagram"

[api]
enabled = true
# Port to use for the API URL.
port = 54321
# Schemas to expose in your API. Tables, views and stored procedures in this schema will get API
# endpoints. `public` and `graphql_public` schemas are included by default.
schemas = ["public", "graphql_public"]
# Extra schemas to add to the search_path of every request.
extra_search_path = ["public", "extensions"]
# The maximum number of rows returns from a view, table, or stored procedure. Limits payload size
# for accidental or malicious requests.
max_rows = 1000

[api.tls]
# Enable HTTPS endpoints locally using a self-signed certificate.
enabled = false

[db]
# Port to use for the local database URL.
port = 54322
# Port used by db diff command to initialize the shadow database.
shadow_port = 54320
# The database major version to use. This has to be the same as your remote database's. Run `SHOW
# server_version;` on the remote database to check.
major_version = 15

[db.pooler]
enabled = false
# Port to use for the local connection pooler.
port = 54329
# Specifies when a server connection can be reused by other clients.
# Configure one of the supported pooler modes: `transaction`, `session`.
pool_mode = "transaction"
# How many server connections to allow per user/database pair.
default_pool_size = 20
# Maximum number of client connections allowed.
max_client_conn = 100

# [db.vault]
# secret_key = "env(SECRET_VALUE)"

[db.migrations]
# Specifies an ordered list of schema files that describe your database.
# Supports glob patterns relative to supabase directory: "./schemas/*.sql"
schema_paths = []

[db.seed]
# If enabled, seeds the database after migrations during a db reset.
enabled = true
# Specifies an ordered list of seed files to load during db reset.
# Supports glob patterns relative to supabase directory: "./seeds/*.sql"
sql_paths = ["./seed.sql"]

[realtime]
enabled = true
# Bind realtime via either IPv4 or IPv6. (default: IPv4)
# ip_version = "IPv6"
# The maximum length in bytes of HTTP request headers. (default: 4096)
# max_header_length = 4096

[studio]
enabled = true
# Port to use for Supabase Studio.
port = 54323
# External URL of the API server that frontend connects to.
api_url = "http://127.0.0.1"
# OpenAI API Key to use for Supabase AI in the Supabase Studio.
openai_api_key = "env(OPENAI_API_KEY)"

# Email testing server. Emails sent with the local dev setup are not actually sent - rather, they
# are monitored, and you can view the emails that would have been sent from the web interface.
[inbucket]
enabled = true
# Port to use for the email testing server web interface.
port = 54324
# Uncomment to expose additional ports for testing user applications that send emails.
# smtp_port = 54325
# pop3_port = 54326
# admin_email = "admin@email.com"
# sender_name = "Admin"

[storage]
enabled = true
# The maximum file size allowed (e.g. "5MB", "500KB").
file_size_limit = "50MiB"

# Image transformation API is available to Supabase Pro plan.
# [storage.image_transformation]
# enabled = true

# Uncomment to configure local storage buckets
# [storage.buckets.images]
# public = false
# file_size_limit = "50MiB"
# allowed_mime_types = ["image/png", "image/jpeg"]
# objects_path = "./images"

[auth]
enabled = true
# The base URL of your website. Used as an allow-list for redirects and for constructing URLs used
# in emails.
site_url = "http://127.0.0.1:3000"
# A list of *exact* URLs that auth providers are permitted to redirect to post authentication.
additional_redirect_urls = ["https://127.0.0.1:3000"]
# How long tokens are valid for, in seconds. Defaults to 3600 (1 hour), maximum 604,800 (1 week).
jwt_expiry = 3600
# If disabled, the refresh token will never expire.
enable_refresh_token_rotation = true
# Allows refresh tokens to be reused after expiry, up to the specified interval in seconds.
# Requires enable_refresh_token_rotation = true.
refresh_token_reuse_interval = 10
# Allow/disallow new user signups to your project.
enable_signup = true
# Allow/disallow anonymous sign-ins to your project.
enable_anonymous_sign_ins = false
# Allow/disallow testing manual linking of accounts
enable_manual_linking = false
# Passwords shorter than this value will be rejected as weak. Minimum 6, recommended 8 or more.
minimum_password_length = 6
# Passwords that do not meet the following requirements will be rejected as weak. Supported values
# are: `letters_digits`, `lower_upper_letters_digits`, `lower_upper_letters_digits_symbols`
password_requirements = ""

[auth.rate_limit]
# Number of emails that can be sent per hour. Requires auth.email.smtp to be enabled.
email_sent = 2
# Number of SMS messages that can be sent per hour. Requires auth.sms to be enabled.
sms_sent = 30
# Number of anonymous sign-ins that can be made per hour per IP address. Requires enable_anonymous_sign_ins = true.
anonymous_users = 30
# Number of sessions that can be refreshed in a 5 minute interval per IP address.
token_refresh = 150
# Number of sign up and sign-in requests that can be made in a 5 minute interval per IP address (excludes anonymous users).
sign_in_sign_ups = 30
# Number of OTP / Magic link verifications that can be made in a 5 minute interval per IP address.
token_verifications = 30
# Number of Web3 logins that can be made in a 5 minute interval per IP address.
web3 = 30

# Configure one of the supported captcha providers: `hcaptcha`, `turnstile`.
# [auth.captcha]
# enabled = true
# provider = "hcaptcha"
# secret = ""

[auth.email]
# Allow/disallow new user signups via email to your project.
enable_signup = true
# If enabled, a user will be required to confirm any email change on both the old, and new email
# addresses. If disabled, only the new email is required to confirm.
double_confirm_changes = true
# If enabled, users need to confirm their email address before signing in.
enable_confirmations = false
# If enabled, users will need to reauthenticate or have logged in recently to change their password.
secure_password_change = false
# Controls the minimum amount of time that must pass before sending another signup confirmation or password reset email.
max_frequency = "1s"
# Number of characters used in the email OTP.
otp_length = 6
# Number of seconds before the email OTP expires (defaults to 1 hour).
otp_expiry = 3600

# Use a production-ready SMTP server
# [auth.email.smtp]
# enabled = true
# host = "smtp.sendgrid.net"
# port = 587
# user = "apikey"
# pass = "env(SENDGRID_API_KEY)"
# admin_email = "admin@email.com"
# sender_name = "Admin"

# Uncomment to customize email template
# [auth.email.template.invite]
# subject = "You have been invited"
# content_path = "./supabase/templates/invite.html"

[auth.sms]
# Allow/disallow new user signups via SMS to your project.
enable_signup = false
# If enabled, users need to confirm their phone number before signing in.
enable_confirmations = false
# Template for sending OTP to users
template = "Your code is {{ .Code }}"
# Controls the minimum amount of time that must pass before sending another sms otp.
max_frequency = "5s"

# Use pre-defined map of phone number to OTP for testing.
# [auth.sms.test_otp]
# 4152127777 = "123456"

# Configure logged in session timeouts.
# [auth.sessions]
# Force log out after the specified duration.
# timebox = "24h"
# Force log out if the user has been inactive longer than the specified duration.
# inactivity_timeout = "8h"

# This hook runs before a token is issued and allows you to add additional claims based on the authentication method used.
# [auth.hook.custom_access_token]
# enabled = true
# uri = "pg-functions://<database>/<schema>/<hook_name>"

# Configure one of the supported SMS providers: `twilio`, `twilio_verify`, `messagebird`, `textlocal`, `vonage`.
[auth.sms.twilio]
enabled = false
account_sid = ""
message_service_sid = ""
# DO NOT commit your Twilio auth token to git. Use environment variable substitution instead:
auth_token = "env(SUPABASE_AUTH_SMS_TWILIO_AUTH_TOKEN)"

# Multi-factor-authentication is available to Supabase Pro plan.
[auth.mfa]
# Control how many MFA factors can be enrolled at once per user.
max_enrolled_factors = 10

# Control MFA via App Authenticator (TOTP)
[auth.mfa.totp]
enroll_enabled = false
verify_enabled = false

# Configure MFA via Phone Messaging
[auth.mfa.phone]
enroll_enabled = false
verify_enabled = false
otp_length = 6
template = "Your code is {{ .Code }}"
max_frequency = "5s"

# Configure MFA via WebAuthn
# [auth.mfa.web_authn]
# enroll_enabled = true
# verify_enabled = true

# Use an external OAuth provider. The full list of providers are: `apple`, `azure`, `bitbucket`,
# `discord`, `facebook`, `github`, `gitlab`, `google`, `keycloak`, `linkedin_oidc`, `notion`, `twitch`,
# `twitter`, `slack`, `spotify`, `workos`, `zoom`.
[auth.external.apple]
enabled = false
client_id = ""
# DO NOT commit your OAuth provider secret to git. Use environment variable substitution instead:
secret = "env(SUPABASE_AUTH_EXTERNAL_APPLE_SECRET)"
# Overrides the default auth redirectUrl.
redirect_uri = ""
# Overrides the default auth provider URL. Used to support self-hosted gitlab, single-tenant Azure,
# or any other third-party OIDC providers.
url = ""
# If enabled, the nonce check will be skipped. Required for local sign in with Google auth.
skip_nonce_check = false

# Allow Solana wallet holders to sign in to your project via the Sign in with Solana (SIWS, EIP-4361) standard.
# You can configure "web3" rate limit in the [auth.rate_limit] section and set up [auth.captcha] if self-hosting.
[auth.web3.solana]
enabled = false

# Use Firebase Auth as a third-party provider alongside Supabase Auth.
[auth.third_party.firebase]
enabled = false
# project_id = "my-firebase-project"

# Use Auth0 as a third-party provider alongside Supabase Auth.
[auth.third_party.auth0]
enabled = false
# tenant = "my-auth0-tenant"
# tenant_region = "us"

# Use AWS Cognito (Amplify) as a third-party provider alongside Supabase Auth.
[auth.third_party.aws_cognito]
enabled = false
# user_pool_id = "my-user-pool-id"
# user_pool_region = "us-east-1"

# Use Clerk as a third-party provider alongside Supabase Auth.
[auth.third_party.clerk]
enabled = false
# Obtain from https://clerk.com/setup/supabase
# domain = "example.clerk.accounts.dev"

[edge_runtime]
enabled = true
# Configure one of the supported request policies: `oneshot`, `per_worker`.
# Use `oneshot` for hot reload, or `per_worker` for load testing.
policy = "oneshot"
# Port to attach the Chrome inspector for debugging edge functions.
inspector_port = 8083
# The Deno major version to use.
deno_version = 1

# [edge_runtime.secrets]
# secret_key = "env(SECRET_VALUE)"

[analytics]
enabled = true
port = 54327
# Configure one of the supported backends: `postgres`, `bigquery`.
backend = "postgres"

# Experimental features may be deprecated any time
[experimental]
# Configures Postgres storage engine to use OrioleDB (S3)
orioledb_version = ""
# Configures S3 bucket URL, eg. <bucket_name>.s3-<region>.amazonaws.com
s3_host = "env(S3_HOST)"
# Configures S3 bucket region, eg. us-east-1
s3_region = "env(S3_REGION)"
# Configures AWS_ACCESS_KEY_ID for S3 bucket
s3_access_key = "env(S3_ACCESS_KEY)"
# Configures AWS_SECRET_ACCESS_KEY for S3 bucket
s3_secret_key = "env(S3_SECRET_KEY)"
</file>

<file path="admin/admin/src/app/dashboard/page.tsx">
'use client'

import { useState, useEffect } from 'react'
import { BarChart } from '@/components/ui/bar-chart'
import { LineChart } from '@/components/ui/line-chart'
import { PieChart } from '@/components/ui/pie-chart'
import { Card } from '@/components/ui/card'
import { ChartControls } from '@/components/chart-controls'
import { getAnalytics, getDashboardAnalytics } from '@/lib/actions'

type TriggerUsage = Array<{ date: string; count: number }>
type DashboardAnalytics = {
  triggerActivations: number
  userActivity: {
    totalUsers: number
    activeUsers: number
  }
  templateUsage: Array<{ name: string; count: number }>
}

export default function DashboardPage() {
  const [isLoading, setIsLoading] = useState(true)
  const [dateRange, setDateRange] = useState('7d')
  const [chartType, setChartType] = useState('bar')
  const [visibleData, setVisibleData] = useState(['Triggers', 'Users', 'Templates'])
  const [chartData, setChartData] = useState<{
    triggerUsage: TriggerUsage
    analytics: DashboardAnalytics | null
  }>({
    triggerUsage: [],
    analytics: null
  })

  useEffect(() => {
    const fetchData = async () => {
      setIsLoading(true)
      try {
        const [basicAnalytics, dashboardAnalytics] = await Promise.all([
          getAnalytics(),
          getDashboardAnalytics()
        ])
        // Convert triggerUsage counts to numbers
        const typedTriggerUsage = basicAnalytics.triggerUsage.map(item => ({
          date: item.date,
          count: Number(item.count)
        }))
        setChartData({
          triggerUsage: typedTriggerUsage,
          analytics: dashboardAnalytics
        })
      } catch (error) {
        console.error('Error fetching analytics:', error)
      } finally {
        setIsLoading(false)
      }
    }

    fetchData()
  }, [dateRange])

  if (isLoading) {
    return (
      <div className="p-6">
        <h1 className="text-2xl font-bold mb-4">Analytics Dashboard</h1>
        <div className="animate-pulse space-y-4">
          <div className="h-8 bg-gray-200 rounded w-32"></div>
          <div className="h-64 bg-gray-200 rounded"></div>
        </div>
      </div>
    )
  }

  return (
    <div className="p-6 space-y-6">
      <div className="flex justify-between items-start gap-4 flex-wrap">
        <h1 className="text-2xl font-bold">Analytics Dashboard</h1>
        <ChartControls
          dateRange={dateRange}
          onDateRangeChange={setDateRange}
          chartType={chartType}
          onChartTypeChange={setChartType}
          visibleData={visibleData}
          onVisibleDataChange={setVisibleData}
        />
      </div>

      <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
        <Card>
          <h2 className="text-lg mb-4">Trigger Activity</h2>
          {chartType === 'bar' && (
            <BarChart
              datasets={chartData.triggerUsage}
              xAxis="date"
              yFields={['count']}
            />
          )}
          {chartType === 'line' && (
            <LineChart
              datasets={chartData.triggerUsage}
              xAxis="date"
              yFields={['count']}
            />
          )}
          {chartType === 'pie' && (
            <PieChart
              datasets={chartData.triggerUsage}
              labelField="date"
              valueField="count"
            />
          )}
        </Card>

        <Card>
          <h2 className="text-lg mb-4">User Activity</h2>
          {chartData.analytics && (
            <LineChart
              datasets={[
                { total: chartData.analytics.userActivity.totalUsers },
                { active: chartData.analytics.userActivity.activeUsers }
              ]}
              xAxis="date"
              yFields={['total', 'active']}
              colors={['#3b82f6', '#10b981']}
            />
          )}
        </Card>

        <Card className="md:col-span-2">
          <h2 className="text-lg mb-4">Template Usage</h2>
          {chartData.analytics && (
            <div className="max-w-md mx-auto">
              <PieChart
                datasets={chartData.analytics.templateUsage}
                labelField="name"
                valueField="count"
              />
            </div>
          )}
        </Card>
      </div>
    </div>
  )
}
</file>

<file path="bot-monitor/service.ts">
import { BotHealthStatus, ActivityEvent, RateLimitConfig } from './types';

const HEALTH_CHECK_INTERVAL = 30000;
const MAX_CONSECUTIVE_FAILURES = 3;
const DEFAULT_RATE_LIMIT: RateLimitConfig = {
  maxEvents: 1000,
  timeWindow: 60 * 60 * 1000 // 1 hour
};

export class BotMonitor {
  private healthStatus: BotHealthStatus;
  private activityLog: ActivityEvent[] = [];
  private consecutiveFailures = 0;
  private rateLimitConfig: RateLimitConfig;
  private eventCount = 0;
  private lastReset = Date.now();

  constructor(private botEndpoint: string, rateLimit?: RateLimitConfig) {
    this.healthStatus = {
      lastPing: new Date(),
      isHealthy: true,
      errorCount: 0
    };
    this.rateLimitConfig = rateLimit || DEFAULT_RATE_LIMIT;
  }

  start(): void {
    console.log('Bot monitoring service started');
    setInterval(() => this.checkHealth(), HEALTH_CHECK_INTERVAL);
  }

  private async checkHealth(): Promise<void> {
    try {
      const response = await fetch(this.botEndpoint + '/health');
      if (!response.ok) throw new Error('Health check failed');
      
      this.consecutiveFailures = 0;
      this.healthStatus = {
        lastPing: new Date(),
        isHealthy: true,
        errorCount: this.healthStatus.errorCount
      };
    } catch (error) {
      this.consecutiveFailures++;
      this.healthStatus = {
        lastPing: new Date(),
        isHealthy: false,
        errorCount: this.healthStatus.errorCount + 1
      };

      this.trackError(error);

      if (this.consecutiveFailures >= MAX_CONSECUTIVE_FAILURES) {
        this.handleCriticalFailure();
      }
    }
  }

  private handleCriticalFailure(): void {
    this.trackActivity({
      type: 'error',
      details: 'Critical failure threshold reached. Initiating recovery.'
    });
    
    // TODO: Implement actual recovery procedures
    console.error('Critical bot failure detected. Recovery needed.');
  }

  private checkRateLimit(): boolean {
    const now = Date.now();
    if (now - this.lastReset > this.rateLimitConfig.timeWindow) {
      this.eventCount = 0;
      this.lastReset = now;
    }
    return this.eventCount < this.rateLimitConfig.maxEvents;
  }

  trackActivity(event: Omit<ActivityEvent, 'timestamp'>): void {
    if (!this.checkRateLimit()) {
      console.warn('Rate limit exceeded for activity tracking');
      return;
    }

    this.eventCount++;
    this.activityLog.push({
      ...event,
      timestamp: new Date()
    });
  }

  trackMessage(content: string, recipient: string, messageId: string): void {
    this.trackActivity({
      type: 'message',
      details: `Message sent to ${recipient}`,
      metadata: {
        recipient,
        messageId,
        content
      }
    });
  }

  trackError(error: Error): void {
    this.trackActivity({
      type: 'error',
      details: error.message,
      metadata: {
        errorStack: error.stack
      }
    });
  }

  trackResponseTime(action: string, responseTime: number): void {
    this.trackActivity({
      type: 'response',
      details: `${action} response time`,
      metadata: {
        responseTime
      }
    });
  }

  getRecentActivity(count = 10): ActivityEvent[] {
    return this.activityLog.slice(-count);
  }

  getCurrentHealth(): BotHealthStatus {
    return this.healthStatus;
  }
}
</file>

<file path="README.md">
# Instagram Comment-to-DM Bot System

Automatically send DMs to users who comment with specific keywords on Instagram posts. Includes an admin panel for managing triggers and responses.

## Features
- Instagram bot service (Python)
- Admin web panel (Next.js)
- Supabase backend (Auth, Database, Storage)
- Dockerized development environment

## Prerequisites
- Docker and Docker Compose
- Instagram API credentials
- Supabase account

## Getting Started

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/arina_admin_instagram.git
   cd arina_admin_instagram
   ```

2. **Set up environment variables**
   - Copy `.env.example` to `.env` in both `admin/admin` and bot directories
   - Fill in your credentials:
     - Instagram API keys
     - Supabase URL and anon key
     - Admin panel secret keys

3. **Start the system**
   ```bash
   docker-compose up --build
   ```

4. **Access the services**
   - Admin panel: http://localhost:3111
   - Bot logs: `docker-compose logs bot`

## Configuration

### Admin Panel
1. Visit http://localhost:3111/login
2. Create your admin account
3. Configure:
   - Instagram posts to monitor
   - Trigger keywords
   - DM response templates

### Instagram Bot
1. Ensure your Instagram account is properly authenticated
2. The bot will automatically:
   - Monitor specified posts
   - Detect trigger keywords
   - Send configured DM responses

## Troubleshooting

**Common Issues:**
- Instagram API limits: Ensure proper rate limiting
- Database connection: Verify Supabase credentials
- Docker issues: Check container logs with `docker-compose logs`

For full documentation, see the `/documentation` directory.
</file>

<file path="todos/dev_todo_phase_2.md">
# Phase 2: Admin Dashboard Functionality - Trigger Management

## 0. Create Button Component (Completed)
- **Implement Component:** Created `src/components/ui/button.tsx`
- **Basic Features:**
  - Variants: primary, secondary, outline
  - Sizes: sm, md, lg
  - Loading state
  - Icon support

## 1. Create Triggers Page
- **Prerequisite:** Button component must exist
- **Implement Route:** Create `src/app/dashboard/triggers/page.tsx`
- **Page Structure:** 
  - Header with title "Trigger Management" and "Create New" button
  - Table showing existing triggers with columns: Keyword, Post ID, Status, Actions
  - Modal for creating/editing triggers

```tsx
// Sample starter code for page.tsx
export default function TriggersPage() {
  return (
    <div className="p-6">
      <div className="flex justify-between items-center mb-6">
        <h1 className="text-2xl font-bold">Trigger Management</h1>
        <Button>Create New Trigger</Button>
      </div>
      {/* Trigger list table */}
    </div>
  )
}
```

## 2. Implement CRUD Operations
- **Create Server Actions:** Add to `src/lib/actions.ts`
```ts
// Create trigger
export async function createTrigger(formData: FormData) {
  // Validate input
  // Insert into database
}

// Update trigger 
export async function updateTrigger(id: string, formData: FormData) {
  // Validate input
  // Update database
}

// Delete trigger
export async function deleteTrigger(id: string) {
  // Delete from database
}
```

## 3. Build Trigger Form Component
- **Create:** `src/components/trigger-form.tsx`
- **Fields:**
  - Keyword (required)
  - Post ID (required)
  - Status toggle (active/inactive)
  - Template selection dropdown

## 4. Add Navigation Link
- **Update:** `src/components/sidebar.tsx`
```tsx
<Link href="/dashboard/triggers" className="flex items-center gap-2">
  <IconTrigger />
  Triggers
</Link>
```

## 5. Validation
- **Add Zod schema:** `src/lib/validators.ts`
```ts
export const triggerSchema = z.object({
  keyword: z.string().min(2),
  postId: z.string().min(1),
  isActive: z.boolean(),
  templateId: z.string().uuid()
});
```

## Verification
- **Test Cases:**
  - Can create new triggers through UI
  - Existing triggers display in table
  - Edit form pre-populates correctly
  - Deletion works with confirmation
  - Validation errors show properly
</file>

<file path="todos/dev_todo_phase_3.md">
# Phase 3: Template Management Implementation

## 1. Create Template Model CRUD Operations ✅
- **Modified `admin/admin/src/lib/actions.ts`**:
  - Added createTemplate, updateTemplate, and deleteTemplate functions
  - Implemented Prisma database operations
  - Included Zod schema validation from validators.ts
- **Created `admin/admin/src/lib/validators.ts`**:
  - Defined templateSchema with content, mediaUrl, and isActive fields

```typescript
// Add to existing actions.ts
export async function createTemplate(formData: FormData) {
  const validated = templateSchema.parse(Object.fromEntries(formData));
  return prisma.template.create({ data: validated });
}

export async function updateTemplate(id: string, formData: FormData) {
  const validated = templateSchema.parse(Object.fromEntries(formData));
  return prisma.template.update({ where: { id }, data: validated });
}

export async function deleteTemplate(id: string) {
  return prisma.template.delete({ where: { id } });
}
```

## 2. Implement Templates Page
- **Create `admin/admin/src/app/dashboard/templates/page.tsx`**:
  - Table view of all templates
  - "Create New" button that opens template form modal
  - Action column with edit/delete buttons

```tsx
import { Button } from '@/components/ui/button';
import { Plus } from 'lucide-react';

export default function TemplatesPage() {
  return (
    <div className="p-6">
      <div className="flex justify-between items-center mb-6">
        <h1 className="text-2xl font-bold">Template Management</h1>
        <Button variant="primary">
          <Plus className="mr-2 h-4 w-4" />
          Create New Template
        </Button>
      </div>
      {/* Template list table */}
    </div>
  );
}
```

## 3. Create Template Form Component
- **Create `admin/admin/src/components/template-form.tsx`**:
  - Form fields: content (textarea), mediaUrl (file upload), and status toggle
  - Reuse existing form patterns from trigger management
  - Add markdown support for content field

```tsx
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';

export function TemplateForm({ template }) {
  return (
    <form>
      <Textarea 
        name="content"
        placeholder="Template content"
        defaultValue={template?.content}
      />
      {/* Add media upload and other fields */}
      <Button type="submit">Save Template</Button>
    </form>
  );
}
```

## 4. Add Template Routes to Sidebar
- **Update `admin/admin/src/components/sidebar.tsx`**:
  - Add navigation link to templates page
  - Use consistent styling with other navigation items

```tsx
<Link href="/dashboard/templates" className="flex items-center gap-2 p-2 hover:bg-gray-100 rounded">
  <FileTextIcon className="w-5 h-5" />
  <span>Templates</span>
</Link>
```

## 5. Implement Validation Schema
- **Create `admin/admin/src/lib/validators.ts`**:
  - Add Zod schema for template validation
  - Ensure content has minimum length requirement

```typescript
import { z } from 'zod';

export const templateSchema = z.object({
  content: z.string().min(10, "Content must be at least 10 characters"),
  mediaUrl: z.string().url().optional(),
  isActive: z.boolean().default(true)
});
```

## 6. Update API Documentation
- **Modify `documentation/api_spec.md`**:
  - Add template management endpoints to API documentation
  - Include request/response examples

```markdown
### Template Management
`POST /api/templates`
```json
{
  "content": "Congratulations! You won!",
  "media_url": "https://example.com/prize.jpg"
}
```

## Verification Steps
1. Create new template through UI
2. Verify template appears in database
3. Test edit/delete functionality
4. Confirm validation errors show properly
5. Check API documentation is updated
</file>

<file path="todos/dev_todo_phase_6.md">
# Phase 6: Bot Monitoring Service Implementation

## 1. Create Monitoring Service Structure
- [x] **Create `bot-monitor/service.ts`**:
  - Implement core monitoring class with methods:
    - `start()`: Initialize monitoring
    - `checkHealth()`: Verify bot instances
    - `trackActivity()`: Log bot actions
- [x] **Create `bot-monitor/types.ts`**:
  - Define monitoring interfaces:
    - `BotHealthStatus`
    - `ActivityEvent`

## 2. Implement Health Checks
- [x] **Update `bot-monitor/service.ts`**:
  - Add method to ping bot instances
  - Implement threshold-based alerts
  - Add recovery procedures

## 3. Create Activity Tracking
- [x] **Update `bot-monitor/service.ts`**:
  - Add method to record:
    - Messages sent
    - Errors encountered
    - Response times
  - Implement rate limiting

## 4. Add Dashboard Integration
- **Update `admin/admin/src/app/dashboard/page.tsx`**:
  - Add new section for bot monitoring
  - Display health status and activity metrics
  - Implement real-time updates

## 5. Set Up Logging
- **Create `bot-monitor/logger.ts`**:
  - Implement structured logging
  - Add log rotation
  - Integrate with existing activity logs

## Verification Steps
1. Start bot monitor and verify initialization
2. Simulate bot failures and check alerts
3. Verify dashboard displays monitoring data
4. Check log files for recorded activity
</file>

<file path="admin/admin/src/lib/actions.ts">
// eslint-disable-next-line @typescript-eslint/no-unused-vars
import { createClient } from './supabase'
// eslint-disable-next-line @typescript-eslint/no-unused-vars
import { PrismaClient } from '@prisma/client'
// eslint-disable-next-line @typescript-eslint/no-unused-vars
import { templateSchema } from './validators'

const prisma = new PrismaClient()

export async function getAnalytics() {
  const supabase = createClient()
  const { data, error } = await supabase
    .from('activity_log')
    .select('*')
    .gte('created_at', new Date(Date.now() - 7 * 86400000).toISOString())
  
  if (error) throw error

  // Aggregate data by date
  const groupedData = data.reduce((acc, entry) => {
    const date = new Date(entry.created_at).toLocaleDateString()
    if (!acc[date]) acc[date] = 0
    acc[date] += (entry.action === 'trigger' ? 1 : 0)
    return acc
  }, {})

  // Convert to array format
  const triggerUsage = Object.entries(groupedData).map(([date, count]) => ({
    date,
    count
  }))

  return { triggerUsage }
}

export async function createTrigger(formData: FormData) {
  const supabase = createClient()
  const { data: { user } } = await supabase.auth.getUser()

  if (!user) {
    throw new Error('User not authenticated')
  }

  const triggerData = {
    postId: formData.get('postId') as string,
    keyword: formData.get('keyword') as string,
    isActive: formData.get('isActive') === 'on',
    userId: user.id,
    templateId: formData.get('templateId') as string
  }

  try {
    const newTrigger = await prisma.trigger.create({
      data: triggerData
    })
    return newTrigger
  } catch (error) {
    console.error('Error creating trigger:', error)
    throw error
  }
}

export async function createTemplate(formData: FormData) {
  const validated = templateSchema.parse(Object.fromEntries(formData));
  try {
    return await prisma.template.create({ data: validated });
  } catch (error) {
    console.error('Error creating template:', error);
    throw error;
  }
}

export async function updateTemplate(id: string, formData: FormData) {
  const validated = templateSchema.parse(Object.fromEntries(formData));
  try {
    return await prisma.template.update({
      where: { id },
      data: validated
    });
  } catch (error) {
    console.error('Error updating template:', error);
    throw error;
  }
}

export async function deleteTemplate(id: string) {
  try {
    return await prisma.template.delete({ where: { id } });
  } catch (error) {
    console.error('Error deleting template:', error);
    throw error;
  }
}

export async function getDashboardAnalytics() {
  try {
    // Get trigger activation counts
    const triggerActivations = await prisma.trigger.count({
      where: { isActive: true }
    })

    // Get user activity metrics
    const totalUsers = await prisma.user.count()
    const activeUsers = await prisma.user.count({
      where: {
        lastLogin: {
          gte: new Date(Date.now() - 7 * 86400000) // Last 7 days
        }
      }
    })

    // Get template usage stats
    const templateUsage = await prisma.template.findMany({
      select: {
        name: true,
        _count: {
          select: { triggers: true }
        }
      },
      orderBy: {
        triggers: {
          _count: 'desc'
        }
      },
      take: 5
    })

    return {
      triggerActivations,
      userActivity: {
        totalUsers,
        activeUsers
      },
      templateUsage: templateUsage.map((t: { name: string; _count: { triggers: number } }) => ({
        name: t.name,
        count: t._count.triggers
      }))
    }
  } catch (error) {
    console.error('Error fetching dashboard analytics:', error)
    throw error
  }
}
</file>

<file path="admin/admin/package.json">
{
  "name": "admin",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev --turbopack",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@prisma/client": "^6.9.0",
    "@supabase/auth-helpers-nextjs": "^0.10.0",
    "@supabase/ssr": "^0.6.1",
    "@supabase/supabase-js": "^2.50.0",
    "chart.js": "^4.4.9",
    "clsx": "^2.1.1",
    "lucide-react": "^0.515.0",
    "next": "15.3.3",
    "prisma": "^6.9.0",
    "react": "^19.0.0",
    "react-chartjs-2": "^5.3.0",
    "react-dom": "^19.0.0",
    "tailwind-merge": "^3.3.1",
    "zod": "^3.25.64"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@tailwindcss/postcss": "^4",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "15.3.3",
    "supabase": "^2.24.3",
    "tailwindcss": "^4",
    "typescript": "^5"
  }
}
</file>

<file path="todos/dev_todo_phase_5.md">
# Phase 5: Analytics Dashboard Implementation

## 1. Enhance Bar Chart Component
- [x] **Update `admin/admin/src/components/ui/bar-chart.tsx`**:
  - Add support for multiple datasets
  - Implement color customization props
  - Add tooltip enhancements

## 2. Create New Chart Components
- [x] **Create `admin/admin/src/components/ui/line-chart.tsx`**:
  - Line chart implementation with similar API to BarChart
- [x] **Create `admin/admin/src/components/ui/pie-chart.tsx`**:
  - Pie/doughnut chart implementation

## 3. Add Analytics Data Fetching
- [x] **Update `admin/admin/src/lib/actions.ts`**:
  - Add `getDashboardAnalytics()` function
  - Query database for:
    - Trigger activation counts
    - User activity metrics
    - Template usage stats

## 4. Enhance Dashboard Page
- [x] **Update `admin/admin/src/app/dashboard/page.tsx`**:
  - Add new chart components
  - Create grid layout for multiple charts
  - Add date range selector
  - Implement data loading states

## 5. Add Chart Customization
- [x] **Create `admin/admin/src/components/chart-controls.tsx`**:
  - Date range picker
  - Chart type selector
  - Data filter options

## Verification Steps
1. Start dev server and navigate to dashboard
2. Verify all charts render without errors
3. Test date range filtering
4. Check data loading states
5. Verify all chart types work properly
</file>

<file path="docker-compose.yml">
version: '3.8'

services:
  admin-panel:
    build: 
      context: ./admin
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgres://postgres:password@db:5433/postgres
    depends_on:
      - db
    volumes:
      - ./admin:/app

  bot-service:
    build: 
      context: ./bot
    environment:
      - INSTAGRAM_USER=${INSTAGRAM_USER:-testuser}
      - INSTAGRAM_PASSWORD=${INSTAGRAM_PASSWORD:-testpass}
    depends_on:
      - db
    volumes:
      - ./bot:/app

  db:
    image: postgres:15
    ports:
      - "5433:5432"
    environment:
      - POSTGRES_PASSWORD=password
    volumes:
      - pgdata:/var/lib/postgresql/data

volumes:
  pgdata:
</file>

<file path="todos/dev_todo_phase_1.md">
# Phase 1: Core Infrastructure Setup - Development Tasks

## 1. Install Required Dependencies
- **Modify `admin/admin/package.json`**:
  Add the following dependencies to the `dependencies` section:
  ```json
  "chart.js": "^4.4.9",
  "react-chartjs-2": "^5.3.0"
  ```
- **Verification**: Run `npm install` in the `admin/admin` directory and confirm both packages are installed.
- **Status**: Completed

## 2. Fix Data Aggregation Logic
- **Modify `admin/admin/src/lib/actions.ts`**:
  Replace the current `getAnalytics` implementation with proper aggregation:
  ```typescript
  export async function getAnalytics() {
    const supabase = createClient();
    const { data, error } = await supabase
      .from('activity_log')
      .select('*')
      .gte('created_at', new Date(Date.now() - 7 * 86400000).toISOString());
    
    if (error) throw error;

    // Aggregate data by date
    const groupedData = data.reduce((acc, entry) => {
      const date = new Date(entry.created_at).toLocaleDateString();
      if (!acc[date]) acc[date] = 0;
      acc[date] += (entry.action === 'trigger' ? 1 : 0);
      return acc;
    }, {});

    // Convert to array format
    const triggerUsage = Object.entries(groupedData).map(([date, count]) => ({
      date,
      count
    }));

    return { triggerUsage };
  }
  ```
- **Verification**: The function should now return aggregated counts per date.
- **Status**: Completed

## 3. Generate Correct Supabase Types
- **Execute Command**:
  Run the following command in the terminal:
  ```bash
  npx supabase gen types typescript --project-id your-project-id > admin/admin/src/types/database.ts
  ```
- **Modify `admin/admin/src/lib/supabase.ts`**:
  Update the import to use the new types:
  ```typescript
  import { Database } from '@/types/database';  // Changed from '@/types/supabase'
  ```
- **Verification**: The `Database` type should now come from `database.ts`.
- **Status**: Completed

## 4. Add Prisma Scripts
- **Modify `admin/admin/package.json`**:
  Add these scripts to the `scripts` section:
  ```json
  "prisma:generate": "prisma generate",
  "prisma:migrate": "prisma migrate dev"
  ```
- **Verification**: Running `npm run prisma:generate` should generate Prisma client.

## 5. Initialize Supabase Database
- **Execute Command**:
  Run database migration:
  ```bash
  docker-compose exec db psql -U postgres -c "CREATE DATABASE arina_admin;"
  npm run prisma:migrate
  ```
- **Verification**: Database tables should match `prisma/schema.prisma`.

## 6. Configure Authentication
- **Modify `admin/admin/src/app/layout.tsx`**:
  Add authentication check to redirect unauthenticated users:
  ```tsx
  import { redirect } from 'next/navigation';
  import { createClient } from '@/lib/supabase';
  
  export default async function RootLayout({ children }) {
    const supabase = createClient();
    const { data: { session } } = await supabase.auth.getSession();
    
    if (!session) {
      redirect('/login');
    }
    
    return (
      // ... existing layout code
    );
  }
  ```
- **Verification**: Unauthenticated users should be redirected to login.

## 7. Update README with Setup Instructions
- **Modify `README.md`**:
  Add environment setup instructions:
  ```markdown
  ## Environment Setup
  
  1. Create `.env.local` in `admin/admin` with:
     ```
     DATABASE_URL="postgres://postgres:password@localhost:5432/arina_admin"
     NEXT_PUBLIC_SUPABASE_URL="http://localhost:5432"
     NEXT_PUBLIC_SUPABASE_KEY="your-anon-key"
     ```
  2. Run database setup: `npm run prisma:migrate`
  ```
- **Verification**: README contains complete setup instructions.
</file>

<file path="todos/master_development_plan.md">
# Master Development Plan

Based on the documentation in the `/documentation` directory, the development will proceed in the following phases:
## Phase 1: Core Infrastructure Setup
- [x] Initialize Supabase database with schema
-极狐
- [x] Configure Next.js application with Supabase integration
- [x] Implement basic authentication system
- [x] Set up Prisma ORM for database access

## Phase 2: Admin Dashboard Functionality (In Progress)
- [x] Implement trigger management (CRUD operations)
  - Detailed tasks created in `todos/dev_todo_phase_2.md`
- [x] Develop template management system
  - Detailed tasks created in `todos/dev_todo_phase_3.md`
- [x] Create activity log display components
  - Detailed tasks created in `todos/dev_todo_phase_4.md`
- [x] Build analytics dashboard with chart visualizations
  - Detailed tasks created in `todos/dev_todo_phase_5.md`

## Phase 3: Bot Engine Implementation
- [x] Develop bot monitoring service architecture
  - Detailed tasks created in `todos/dev_todo_phase_6.md`
- [x] Implement keyword matching logic
  - Detailed tasks created in `todos/dev_todo_phase_7.md`
- [x] Create DM sending functionality
  - Detailed tasks created in `todos/dev_todo_phase_8.md`
- [x] Build logging system for bot activities
  - Detailed tasks created in `todos/dev_todo_phase_9.md`

## Phase 4: API Integration
- [x] Implement REST API for trigger management
  - Detailed tasks created in `todos/dev_todo_phase_10.md`
- [x] Create endpoints for template operations
  - Detailed tasks created in `todos/dev_todo_phase_11.md`
- [x] Develop bot healthcheck API
  - Detailed tasks created in `todos/dev_todo_phase_12.md`
- [ ] Implement authentication for API endpoints

## Phase 5: Testing and Deployment
- [ ] Write comprehensive test suite
- [ ] Create CI/CD pipeline
- [ ] Implement monitoring and alerting
- [ ] Prepare production deployment

Each phase will be broken down into detailed development tasks by the Planner_Architect AI.
</file>

</files>
